{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efa83c46-59cb-4f72-9991-77a7ae6f645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9808884b-772d-4bc5-b94a-7a17d955d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_attribute_dict = {'FL': 'Leaves_fresh', 'ML': 'Leaves_mature', 'DL': 'Leaves_old', \n",
    "                          'BD': 'Flowers_bud', 'OF': 'Flowers_open', 'MF': 'Flowers_male', \n",
    "                          'FF': 'Flowers_Female', 'UFR': 'Fruits_unripe', 'RFR': 'Fruits_ripe', \n",
    "                          'OFR': 'Fruits_open'}\n",
    "code_to_category_dict = {'NA': None, '': None, '0': 0, '1': 1, '2': 2} #TODO - what should map to -1?\n",
    "\n",
    "def code_to_attribute_category_tuple(code):\n",
    "    code_attr_tup = code.split('_')\n",
    "    code_attr_tup[0] = code_to_attribute_dict[code_attr_tup[0]]\n",
    "    code_attr_tup[1] = code_to_category_dict[code_attr_tup[1]]\n",
    "    return tuple(code_attr_tup)\n",
    "\n",
    "def get_duplicates_df(df):\n",
    "    duplicates_df = pd.DataFrame({'species_id': [], 'all_same': []})\n",
    "    for species_id in df['species_id'].unique():\n",
    "        df_filtered = df[df['species_id'] == species_id]\n",
    "        if len(df_filtered) > 1:\n",
    "            # see if categorical vectors are all the same:\n",
    "            all_equal = True\n",
    "            for colname in df.columns[3:-2]:\n",
    "                all_equal = all_equal and df_filtered[colname].nunique() == 1\n",
    "            duplicates_df.loc[len(duplicates_df) + 1] = pd.Series({'species_id': species_id, 'all_same': all_equal})\n",
    "    return duplicates_df\n",
    "\n",
    "def clean_df(df):\n",
    "    # TODO:\n",
    "    # - get rid of null values\n",
    "\n",
    "    # get rid of duplicate rows\n",
    "    print(\"getting rid of duplicates\")\n",
    "    duplicates_df = get_duplicates_df(df)\n",
    "    for i in range(len(duplicates_df)):\n",
    "        dup_id = duplicates_df.iloc[i]['species_id']\n",
    "        drop_idx = list(df['species_id']).index(dup_id)\n",
    "        df = df.drop(index=drop_idx)\n",
    "    print(\"got rid of duplicates\")\n",
    "    # new columns: everything in df that is not a month, plus the 10 categorical codes, plus a 'week' column\n",
    "    week_codes = ['Jan_wk1', 'Jan_wk2', 'Jan_wk3', 'Jan_wk4', 'Feb_wk1', \n",
    "                   'Feb_wk2', 'Feb_wk3', 'Feb_wk4', 'Mar_wk1', 'Mar_wk2',\n",
    "                   'Mar_wk3', 'Mar_wk4', 'Apr_wk1', 'Apr_wk2', 'Apr_wk3', 'Apr_wk4',\n",
    "                   'May_wk1', 'May_wk2', 'May_wk3', 'May_wk4', 'Jun_wk1', 'Jun_wk2',\n",
    "                   'Jun_wk3', 'Jun_wk4', 'Jul_wk1', 'Jul_wk2', 'Jul_wk3', 'Jul_wk4',\n",
    "                   'Aug_wk1', 'Aug_wk2', 'Aug_wk3', 'Aug_wk4', 'Sep_wk1', 'Sep_wk2',\n",
    "                   'Sep_wk3', 'Sep_wk4', 'Oct_wk1', 'Oct_wk2', 'Oct_wk3', 'Oct_wk4',\n",
    "                   'Nov_wk1', 'Nov_wk2', 'Nov_wk3', 'Nov_wk4', 'Dec_wk1', 'Dec_wk2','Dec_wk3', 'Dec_wk4']\n",
    "    \n",
    "    cat_codes = ['Leaves_fresh', 'Leaves_mature', 'Leaves_old', 'Flowers_bud',\n",
    "       'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_unripe',\n",
    "       'Fruits_ripe', 'Fruits_open']\n",
    "\n",
    "    base_cols = [not_week_code for not_week_code in filter(lambda c: c not in week_codes, list(df.columns))]\n",
    "    try:\n",
    "        base_cols.remove('created_at')\n",
    "    except:\n",
    "        print(\"WARNING: created_at column not found\")\n",
    "    \n",
    "    new_cols = base_cols + ['week'] + cat_codes\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=new_cols)\n",
    "\n",
    "    num_idxs = len(df)\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx % 10 == 0:\n",
    "            print(\"{} % done\".format(100 * idx / num_idxs))\n",
    "        for week_idx, week_name in enumerate(week_codes):\n",
    "            new_datapoint = {}\n",
    "            for old_colname in base_cols:\n",
    "                new_datapoint[old_colname] = row[old_colname]\n",
    "            new_datapoint['week'] = week_idx\n",
    "            cat_vector_for_week = row[week_name]\n",
    "\n",
    "            # make nan map to a cat vector of all Nones\n",
    "            # print(type(cat_vector_for_week), cat_vector_for_week)\n",
    "            if not isinstance(cat_vector_for_week, str):\n",
    "                if math.isnan(cat_vector_for_week):\n",
    "                    for attr_name in code_to_attribute_dict.values():\n",
    "                        new_datapoint[attr_name] = None\n",
    "                    new_df.loc[len(new_df)] = new_datapoint\n",
    "                    continue\n",
    "            \n",
    "            cat_vector_list = list(map(code_to_attribute_category_tuple, cat_vector_for_week.split(\",\")))\n",
    "            for (attr, cat) in cat_vector_list:\n",
    "                new_datapoint[attr] = cat\n",
    "\n",
    "            # add new datapoint to df\n",
    "            new_df.loc[len(new_df)] = new_datapoint\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25e76900-7b6a-4c4d-8665-e0428a42426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'reference_data' already exists.\n",
      "cleaning pvt_pvt_haryana.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_manipur.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_delhi.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_tripura.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_odisha.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_tamil_nadu.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_gujarat.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_andhra_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_bihar.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_kerala.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_puducherry.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_meghalaya.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "# clean all old pvt dataframes, put in ./reference_data\n",
    "new_dir_path = 'reference_data'\n",
    "try:\n",
    "    # Create the directory\n",
    "    os.mkdir(new_dir_path)\n",
    "    print(f\"Directory '{new_dir_path}' created.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{new_dir_path}' already exists.\")\n",
    "\n",
    "for tablename in os.listdir('./pvttables_raw/'):\n",
    "    if tablename == '.DS_Store' or tablename in os.listdir('./reference_data/'):\n",
    "        continue\n",
    "    print(\"cleaning {}\".format(tablename))\n",
    "    df = pd.read_csv('./pvttables_raw/{}'.format(tablename), sep=';')\n",
    "    new_df = clean_df(df)\n",
    "    new_df.to_csv('./reference_data/{}'.format(tablename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
