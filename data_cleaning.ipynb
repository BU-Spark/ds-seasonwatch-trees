{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14651e97",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba25580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geopandas in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (0.14.4)\n",
      "Requirement already satisfied: shapely in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (2.0.4)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: numpy>=1.22 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from geopandas) (1.26.3)\n",
      "Requirement already satisfied: packaging in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from geopandas) (2.1.4)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (2024.6.2)\n",
      "Requirement already satisfied: click~=8.0 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr4/ugrad/zmeurer/.local/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.4)\n"
     ]
    }
   ],
   "source": [
    "# This is an uncommon library so we run a pip install of it just in case\n",
    "!pip install geopandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1609308f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import pandas as pd # Pandas for storing and manipulating CSV files as DataFrames (tables)\n",
    "import geopandas as gpd # Geopandas for converting coordinates to states\n",
    "from shapely.geometry import Point # Same as Geopandas\n",
    "import numpy as np # Numpy for storing and manipulating arrays (lists)\n",
    "import math # Math for finding NaN values\n",
    "import os # OS for writing and reading directories (folders)\n",
    "import time # Time for checking how long things take\n",
    "from sklearn.ensemble import IsolationForest # Isolation Forests for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9bffb",
   "metadata": {},
   "source": [
    "# Previewing Original Citizen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef76fac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Observation_ID</th>\n",
       "      <th>Date_of_observation</th>\n",
       "      <th>User_id</th>\n",
       "      <th>User_Tree_id</th>\n",
       "      <th>Species_name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Leaves_fresh</th>\n",
       "      <th>Leaves_mature</th>\n",
       "      <th>Leaves_old</th>\n",
       "      <th>Flowers_bud</th>\n",
       "      <th>Flowers_open</th>\n",
       "      <th>Flowers_male</th>\n",
       "      <th>Flowers_Female</th>\n",
       "      <th>Fruits_unripe</th>\n",
       "      <th>Fruits_ripe</th>\n",
       "      <th>Fruits_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>388564.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84299.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.15386</td>\n",
       "      <td>75.22397</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>388565.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84300.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.15386</td>\n",
       "      <td>75.22397</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>388566.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84301.0</td>\n",
       "      <td>Fish-tail palm- Caryota urens</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>388567.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84302.0</td>\n",
       "      <td>Mast Tree-Monoon longifolium</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>388568.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84303.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Observation_ID Date_of_observation  User_id  User_Tree_id  \\\n",
       "0           1        388564.0          2020-01-01  20396.0       84299.0   \n",
       "1           2        388565.0          2020-01-01  20396.0       84300.0   \n",
       "2           3        388566.0          2020-01-01  20396.0       84301.0   \n",
       "3           4        388567.0          2020-01-01  20396.0       84302.0   \n",
       "4           5        388568.0          2020-01-01  20396.0       84303.0   \n",
       "\n",
       "                        Species_name       Lat      Long State_name  \\\n",
       "0  Indian Almond- Terminalia catappa  12.15386  75.22397     Kerala   \n",
       "1  Indian Almond- Terminalia catappa  12.15386  75.22397     Kerala   \n",
       "2      Fish-tail palm- Caryota urens  12.14060  75.22145     Kerala   \n",
       "3       Mast Tree-Monoon longifolium  12.14060  75.22145     Kerala   \n",
       "4  Indian Almond- Terminalia catappa  12.14060  75.22145     Kerala   \n",
       "\n",
       "   Leaves_fresh  Leaves_mature  Leaves_old  Flowers_bud  Flowers_open  \\\n",
       "0           2.0            0.0         0.0         -2.0          -2.0   \n",
       "1           2.0            0.0         0.0         -2.0          -2.0   \n",
       "2           0.0            2.0         0.0         -2.0          -2.0   \n",
       "3           1.0            2.0         0.0         -2.0          -2.0   \n",
       "4           0.0            1.0         2.0         -2.0          -2.0   \n",
       "\n",
       "   Flowers_male  Flowers_Female  Fruits_unripe  Fruits_ripe  Fruits_open  \n",
       "0          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "1          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "2          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "3          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "4          -2.0            -2.0           -2.0         -2.0         -2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"alldata.csv\") # Load raw citizen data in\n",
    "df.head() # Previewing raw (before cleaning) citizen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353169c4",
   "metadata": {},
   "source": [
    "# Handling Incorrect -2 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5bb3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing incorrect -2 values with either NA or -2\n",
    "all_species = list(df['Species_name'].value_counts().index) # All species names in order of frequency\n",
    "phenophases = list(df.columns[9:]) # Phenophase column names\n",
    "\n",
    "def create_species_dict(*absent_phenophases):\n",
    "    \"\"\"\n",
    "    Creates a dictionary informing if each phenophase is seen in a species or not (0 for seen, 1 for not seen)\n",
    "\n",
    "    Args:\n",
    "        absent_phenophase (List(string)): List of phenophases not seen in a species\n",
    "    Returns:\n",
    "        species_dict (Dict(string,int)): A Dictionary mapping phenophases to binaries indicating presence in a species\n",
    "    \"\"\"\n",
    "    species_dict = dict(zip(phenophases, np.zeros(len(phenophases), int)))\n",
    "    for phenophase in absent_phenophases:\n",
    "        species_dict[phenophase] = 1\n",
    "    return species_dict\n",
    "\n",
    "handbook_dicts = {} # Dict mapping species to species dicts. \n",
    "# Below are manually input absent phenophases for each species in the citizen dataset. Labels derived from SeasonWatch Tree Phenology Guide\n",
    "handbook_dicts[all_species[0]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[1]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[2]] = create_species_dict('Flowers_open', 'Fruits_open')\n",
    "handbook_dicts[all_species[3]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[4]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[5]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[6]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[7]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[8]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[9]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[10]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[11]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[12]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[13]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[14]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[15]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[16]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[17]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[18]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[19]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[20]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[21]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[22]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[23]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[24]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[25]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[26]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[27]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[28]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[29]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[30]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[31]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[32]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[33]] = create_species_dict('Flowers_bud', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[34]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[35]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[36]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[37]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[38]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[39]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[40]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[41]] = create_species_dict('Flowers_open', 'Fruits_open')\n",
    "handbook_dicts[all_species[42]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[43]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[44]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[45]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[46]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[47]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[48]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[49]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[50]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[51]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[52]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[53]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[54]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[55]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[56]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[57]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[58]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[59]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[60]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[61]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[62]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[63]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[64]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[65]] = create_species_dict('Flowers_open', 'Fruits_open') # Silkworm Mulberry\n",
    "handbook_dicts[all_species[66]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[67]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[68]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[69]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[70]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[71]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[72]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[73]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[74]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[75]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[76]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[77]] = create_species_dict('Flowers_open', 'Fruits_open') # Box-myrtle\n",
    "handbook_dicts[all_species[78]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[79]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[80]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Airi Mango\n",
    "handbook_dicts[all_species[81]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[82]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[83]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[84]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[85]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[86]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[87]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[88]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[89]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[90]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[91]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[92]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[93]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[94]] = create_species_dict('Flowers_open') # Wild Almond\n",
    "handbook_dicts[all_species[95]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[96]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[97]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[98]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[99]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[100]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[101]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[102]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[103]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[104]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Alphonso Mango\n",
    "handbook_dicts[all_species[105]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[106]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[107]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[108]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[109]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[110]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[111]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[112]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[113]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[114]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[115]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Aabehayat Mango\n",
    "handbook_dicts[all_species[116]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[117]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[118]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[119]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[120]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[121]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[122]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[123]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[124]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[125]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[126]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[127]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[128]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[129]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Manjeera Mango\n",
    "handbook_dicts[all_species[130]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[131]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[132]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[133]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[134]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[135]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[136]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[137]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[138]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[139]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[140]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[141]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[142]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[143]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[144]] = create_species_dict('Flowers_male', 'Flowers_Female') # Blue Pine\n",
    "handbook_dicts[all_species[145]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[146]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[147]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[148]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[149]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[150]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[151]] = create_species_dict('Flowers_open', 'Fruits_open') # Indian Charcoal Tree\n",
    "handbook_dicts[all_species[152]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[153]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[154]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[155]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[156]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[157]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[158]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[159]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[160]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Mallika Mango\n",
    "handbook_dicts[all_species[161]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[162]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[163]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[164]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[165]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[166]] = create_species_dict('Flowers_open','Fruits_open') # Mohru Oak\n",
    "handbook_dicts[all_species[167]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[168]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[169]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[170]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[171]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[172]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Chosa Mango\n",
    "handbook_dicts[all_species[173]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[174]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Olour Mango\n",
    "handbook_dicts[all_species[175]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[176]] = create_species_dict('Flowers_bud', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "\n",
    "# Replace Incorrect -2 Values\n",
    "for species in all_species:\n",
    "    species_df = df[df['Species_name'] == species]\n",
    "    species_dict = handbook_dicts[species]\n",
    "    for phenophase in phenophases:\n",
    "        if species_dict[phenophase] == 0: # Phenophase seen in species\n",
    "            false_positive_idx = species_df.index[species_df[phenophase] == -2] # Indices of reports that incorrectly assign -2 values (false positive) to phenophases SEEN in the species\n",
    "            df.loc[false_positive_idx, phenophase] = np.full(len(false_positive_idx),np.nan) # Turn all false positives into NaN values (these observations will later be dropped)\n",
    "        if species_dict[phenophase] == 1: # Phenophase NOT seen in species\n",
    "            false_negative_idx = species_df.index[species_df[phenophase] != -2] # Indices of reports that incorrectly assign values other than -2 (false negative) to phenophases NOT SEEN in the species\n",
    "            df.loc[false_negative_idx, phenophase] = np.full(len(false_negative_idx),-2.0) # Turn all false negatives into -2 values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7a26e",
   "metadata": {},
   "source": [
    "# Combining Mango Varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f675e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combining all mango varieties under the Species_name of Mango (all varieties)- Mangifera indica\n",
    "df['Species_name'] = df['Species_name'].replace(to_replace=r'\\w* Mango- Mangifera indica', value='Mango (all varieties)- Mangifera indica', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56c03",
   "metadata": {},
   "source": [
    "# Filling in Missing States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c330e936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_shapefile = gpd.read_file(\"india_map/gadm41_IND_3.shp\") # Load map of India with states as a coordinate grid with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bd420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamil Nadu\n"
     ]
    }
   ],
   "source": [
    "# Function for filling state_name attribute based on coordinates for observations with NA state_name\n",
    "def find_indian_state(latitude, longitude, gdf):\n",
    "    \"\"\"\n",
    "    Finds the state name associated with a set of coordinates\n",
    "\n",
    "    Args:\n",
    "        latitude, longitude (int, int): Latitude and longitude coordinates\n",
    "        gdf (GeoDataFrame): Coordinate grid of India with states labeled\n",
    "    Returns:\n",
    "        state['NAME_1'] (string): If coordinates map to somewhere within India, return state name\n",
    "        None (None): Else, return None because the coordinates are unreliable\n",
    "    \"\"\"\n",
    "    \n",
    "    point = Point(longitude, latitude)\n",
    "    \n",
    "    for _, state in gdf.iterrows():\n",
    "        if state['geometry'].contains(point):\n",
    "            return state['NAME_1']\n",
    "    return None\n",
    "\n",
    "# Test\n",
    "state = find_indian_state(13.07248, 80.24340, states_shapefile)\n",
    "print(state) # IF THE FUNCTION WORKS THIS SHOULD OUTPUT TAMIL NADU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "309f4775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.03274178504943848 seconds elapsed; 0.0% Done\n",
      "1000: 44.41838049888611 seconds elapsed; 6.737636437137852% Done\n",
      "2000: 85.58362030982971 seconds elapsed; 13.475272874275705% Done\n",
      "3000: 129.2868480682373 seconds elapsed; 20.212909311413558% Done\n",
      "4000: 171.94020986557007 seconds elapsed; 26.95054574855141% Done\n",
      "5000: 217.25530767440796 seconds elapsed; 33.68818218568926% Done\n",
      "6000: 265.74258041381836 seconds elapsed; 40.425818622827116% Done\n",
      "7000: 322.73581433296204 seconds elapsed; 47.16345505996497% Done\n",
      "8000: 376.08195328712463 seconds elapsed; 53.90109149710282% Done\n",
      "9000: 423.34649181365967 seconds elapsed; 60.63872793424066% Done\n",
      "10000: 469.84784054756165 seconds elapsed; 67.37636437137851% Done\n",
      "11000: 524.9627561569214 seconds elapsed; 74.11400080851637% Done\n",
      "12000: 581.1997730731964 seconds elapsed; 80.85163724565423% Done\n",
      "13000: 618.7815957069397 seconds elapsed; 87.58927368279208% Done\n",
      "14000: 655.1294839382172 seconds elapsed; 94.32691011992993% Done\n",
      "Finished in 688.5286242961884 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fill any missing state names in dataset\n",
    "import time \n",
    "start_time = time.time() # Measuring Time\n",
    "counter = 0 # Number of observations checked so far\n",
    "observations_missing_state_name = df[df[\"State_name\"].isna()].drop(['State_name'], axis=1).dropna(how='any') # Taking a subset of citizen observations with all columns recorded (not NaN/Null/None) except State_name\n",
    "for idx, row in observations_missing_state_name.iterrows(): # Iterate over observations missing a state name\n",
    "    if (counter % 1000) == 0: # Report time every 1000 observations\n",
    "        print(f\"{counter}: {time.time()-start_time} seconds elapsed; {counter/len(observations_missing_state_name)*100}% Done\")\n",
    "    df.at[idx, \"State_name\"] = find_indian_state(row[\"Lat\"], row[\"Long\"], states_shapefile) # Add state name based on coordinates (if coordinates are reliable)\n",
    "    counter += 1\n",
    "# In case any states are labeled as a name inconsistent with our dataset\n",
    "df['State_name'] = df['State_name'].replace('Andaman and Nicobar', 'Andaman and Nicobar Islands') # Two names for Andaman and Nicobar Islands\n",
    "df['State_name'] = df['State_name'].replace('NCT of Delhi', 'Delhi') # Two names for Delhi\n",
    "print(f\"Finished in {time.time()-start_time} seconds\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746623fc",
   "metadata": {},
   "source": [
    "# Dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e449bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop observations with Null/NaN/None values and sort by species name\n",
    "df = df.drop(df.columns[0], axis=1) # Drop the index column called \"Unnamed: 0\"\n",
    "df = df.dropna(how='any') # Drop any observation with at least one NaN/Null/None value reported\n",
    "df = df.sort_values(by='Species_name') # Order data by species for organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a32b7",
   "metadata": {},
   "source": [
    "# Reformatting & Adding Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c7cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformats df to Year, Week formatting to match the reference data\n",
    "df[\"Date_of_observation\"] = pd.to_datetime(df[\"Date_of_observation\"], format='mixed') # Change Date_of_observation column to datetime format/datatype\n",
    "\n",
    "df[\"Year\"] = df[\"Date_of_observation\"].dt.isocalendar().year # Extract the year of each observation from the date column\n",
    "\n",
    "\"\"\"\n",
    "!!! Use the following instead if 52 weeks are wanted !!!\n",
    "df[\"Year\"] = df[\"Date_of_observation\"].dt.isocalendar().week\n",
    "Warning: 52nd week will only be 1 or 2 days depending on if it's a leap year or not\n",
    "\"\"\"\n",
    "\n",
    "# Weeks are 48 weeks instead of 52 because this follows the format of the reference data\n",
    "df[\"Week\"] = df[\"Date_of_observation\"].dt.dayofyear // (366/48+0.0000000000001) # Week durations vary between 7 or 8 days (~50% of weeks are 7 days long. ~50% of weeks are 8 days long)\n",
    "df[\"Week\"] = df[\"Week\"].astype(int) # Convert Week column from decimal to integer\n",
    "\n",
    "\"\"\"\n",
    "dt.dayofyear gives an index starting at 1, thus use 366 in equation for leap years\n",
    "Add 0.0000000000001 bias to 48 (number of weeeks) so week is in range [0,47] instead of [0,48]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b0e3b",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6edfd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(df, num_trees=500): \n",
    "    \"\"\"\n",
    "    Helper function for anomaly_detection_overall. Gives indices of anomalous observations.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Observations spanning at least an entire year. Observations are preferably of the same species within the same state.\n",
    "        num_trees (int): Number of trees making up an isolation forest. Higher number of trees reduces variance but slows down training.\n",
    "    Returns:\n",
    "        invalid_indices (List(int)): Index values in citizen data associated with observations deemed outliers by an isolation forest (invalid).\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.drop([\"Date_of_observation\", \"Observation_ID\", \"User_id\", \"User_Tree_id\", \"State_name\", \"Species_name\", \"Year\"], axis=1) # Drop columns not used in training\n",
    "    \n",
    "    model = IsolationForest(n_estimators = num_trees, contamination = 0.08, verbose = 1, random_state = 42) # Generate isolation forest\n",
    "    # Note: Higher contamination score means more false positive outliers; Lower contamination score means more false negative outliers\n",
    "    \n",
    "    invalid_indices = []\n",
    "    \n",
    "    for week in df[\"Week\"].sort_values().unique(): # Iterate over each week\n",
    "        week_df = df[df[\"Week\"] == week] # Use only observations from the current week\n",
    "        week_df = week_df.drop(\"Week\", axis=1) # Drop week column because it is not used in training\n",
    "        \n",
    "        model.fit(week_df) # Train isolation forest on particular week\n",
    "        preds = model.predict(week_df) # Predict if each observation is an outlier\n",
    "        week_df[\"Predictions\"] = preds # Add prediction to observation data\n",
    "        \n",
    "        invalid_indices += list(week_df[week_df[\"Predictions\"] == -1].index) # Record indices of outliers from the given week\n",
    "    return invalid_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4229edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection_overall(df, min_observations_for_outlier_detection):\n",
    "    \"\"\"\n",
    "    Performs anomaly detection on entire dataset\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): All citizen data\n",
    "        min_observations_for_outlier_detection (int): Minimum number of observations in a subset of the data for anomaly detection to be performed\n",
    "    Returns:\n",
    "        invalid_indices (List(int)): Index values in citizen data associated with observations deemed outliers by isolation forests (invalid).\n",
    "    \"\"\"\n",
    "    start_time = time.time() # Time\n",
    "    invalid_indices = []\n",
    "    states = df[\"State_name\"].unique() # All states in dataset\n",
    "    for state in states: # Iterate over all states\n",
    "        print(f\"**********{state}**********\")\n",
    "        state_start_time = time.time() # Time\n",
    "        state_df = df[df[\"State_name\"] == state] # Only observations from the given state\n",
    "        years = state_df[\"Year\"].sort_values().unique() # All years data was recorded in the given state\n",
    "        for year in years: # Iterate over each year\n",
    "            print(f\"**********{year}**********\")\n",
    "            year_start_time = time.time() # Time\n",
    "            state_year_df = state_df[state_df[\"Year\"] == year] # Only observations in the given year from the given state\n",
    "            species_list = state_year_df[\"Species_name\"].unique() # All species in the given year from the given state\n",
    "            for species in species_list: # Iterate over each species\n",
    "                species_state_year_df = state_year_df[state_year_df[\"Species_name\"] == species] # Only observations of the given species in the given year from the given state\n",
    "                if len(species_state_year_df) > min_observations_for_outlier_detection: # Verifying there are enough observations for anomaly detection\n",
    "                    species_start_time = time.time() # Time\n",
    "                    outliers = outlier_detection(species_state_year_df) # Run outlier detection on observations\n",
    "                    invalid_indices += outliers # Record indices of outliers\n",
    "                    print(f\"{len(outliers)}/{len(species_state_year_df)} observations invalid in {species} in {year} in {state}\") # Outlier count\n",
    "                    print(f\"Finished {species} in {state} during {year} in {time.time()-species_start_time} seconds\") # Time\n",
    "            print(f\"Finished {state} during {year} in {time.time()-year_start_time} seconds\") # Time\n",
    "        print(f\"Finished {state} in {time.time()-state_start_time} seconds\") # Time\n",
    "    print(f\"{len(invalid_indices)}/{len(df)} observations invalid overall\") # Total outlier count\n",
    "    print(f\"Finished completely in {time.time()-start_time} seconds\") # Time\n",
    "    return invalid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "892b31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Kerala**********\n",
      "**********2014**********\n",
      "Finished Kerala during 2014 in 0.0012421607971191406 seconds\n",
      "**********2015**********\n",
      "Finished Kerala during 2015 in 0.0008935928344726562 seconds\n",
      "**********2016**********\n",
      "Finished Kerala during 2016 in 0.0008459091186523438 seconds\n",
      "**********2017**********\n",
      "Finished Kerala during 2017 in 0.003336191177368164 seconds\n",
      "**********2018**********\n",
      "389/4672 observations invalid in Coconut palm-Cocos nucifera in 2018 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2018 in 21.592904090881348 seconds\n",
      "284/3238 observations invalid in Jackfruit- Artocarpus heterophyllus in 2018 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2018 in 21.74365997314453 seconds\n",
      "113/1170 observations invalid in Jamun- Syzygium cumini in 2018 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2018 in 21.25935125350952 seconds\n",
      "227/2596 observations invalid in Mango (all varieties)- Mangifera indica in 2018 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2018 in 21.475406408309937 seconds\n",
      "82/788 observations invalid in Neem- Azadirachta indica in 2018 in Kerala\n",
      "Finished Neem- Azadirachta indica in Kerala during 2018 in 21.05096983909607 seconds\n",
      "Finished Kerala during 2018 in 107.25805640220642 seconds\n",
      "**********2019**********\n",
      "224/2580 observations invalid in Amla- Phyllanthus emblica in 2019 in Kerala\n",
      "Finished Amla- Phyllanthus emblica in Kerala during 2019 in 21.565115928649902 seconds\n",
      "76/895 observations invalid in Chandada- Macaranga peltata in 2019 in Kerala\n",
      "Finished Chandada- Macaranga peltata in Kerala during 2019 in 21.13963532447815 seconds\n",
      "283/3345 observations invalid in Coconut palm-Cocos nucifera in 2019 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2019 in 21.439104795455933 seconds\n",
      "87/819 observations invalid in Copper-pod- Peltophorum pterocarpum in 2019 in Kerala\n",
      "Finished Copper-pod- Peltophorum pterocarpum in Kerala during 2019 in 21.174031496047974 seconds\n",
      "83/869 observations invalid in Devil's tree- Alstonia scholaris in 2019 in Kerala\n",
      "Finished Devil's tree- Alstonia scholaris in Kerala during 2019 in 21.1236789226532 seconds\n",
      "92/841 observations invalid in Drumstick tree-Moringa oleifera in 2019 in Kerala\n",
      "Finished Drumstick tree-Moringa oleifera in Kerala during 2019 in 21.140639305114746 seconds\n",
      "84/784 observations invalid in Guava tree-Psidium guajava in 2019 in Kerala\n",
      "Finished Guava tree-Psidium guajava in Kerala during 2019 in 21.228286266326904 seconds\n",
      "134/1410 observations invalid in Gulmohur- Delonix regia in 2019 in Kerala\n",
      "Finished Gulmohur- Delonix regia in Kerala during 2019 in 21.326239109039307 seconds\n",
      "168/1788 observations invalid in Indian Almond- Terminalia catappa in 2019 in Kerala\n",
      "Finished Indian Almond- Terminalia catappa in Kerala during 2019 in 21.325258493423462 seconds\n",
      "243/2828 observations invalid in Indian laburnum- Cassia fistula in 2019 in Kerala\n",
      "Finished Indian laburnum- Cassia fistula in Kerala during 2019 in 21.66416025161743 seconds\n",
      "722/8929 observations invalid in Jackfruit- Artocarpus heterophyllus in 2019 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2019 in 22.376641035079956 seconds\n",
      "190/2198 observations invalid in Jamun- Syzygium cumini in 2019 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2019 in 21.3976891040802 seconds\n",
      "669/8154 observations invalid in Mango (all varieties)- Mangifera indica in 2019 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2019 in 22.453654050827026 seconds\n",
      "201/2347 observations invalid in Maulsari- Mimusops elengi in 2019 in Kerala\n",
      "Finished Maulsari- Mimusops elengi in Kerala during 2019 in 21.383148908615112 seconds\n",
      "162/1821 observations invalid in Neem- Azadirachta indica in 2019 in Kerala\n",
      "Finished Neem- Azadirachta indica in Kerala during 2019 in 21.32694435119629 seconds\n",
      "92/965 observations invalid in Peepal- Ficus religiosa in 2019 in Kerala\n",
      "Finished Peepal- Ficus religiosa in Kerala during 2019 in 21.2512149810791 seconds\n",
      "106/1107 observations invalid in Purple bauhinia- Bauhinia purpurea in 2019 in Kerala\n",
      "Finished Purple bauhinia- Bauhinia purpurea in Kerala during 2019 in 21.30650019645691 seconds\n",
      "86/914 observations invalid in Quickstick- Gliricidia sepium in 2019 in Kerala\n",
      "Finished Quickstick- Gliricidia sepium in Kerala during 2019 in 21.19770908355713 seconds\n",
      "146/1701 observations invalid in Rain tree-Samanea saman in 2019 in Kerala\n",
      "Finished Rain tree-Samanea saman in Kerala during 2019 in 21.419512271881104 seconds\n",
      "301/3583 observations invalid in Tamarind- Tamarindus indica in 2019 in Kerala\n",
      "Finished Tamarind- Tamarindus indica in Kerala during 2019 in 21.669387340545654 seconds\n",
      "105/1031 observations invalid in True Ashoka- Saraca asoca in 2019 in Kerala\n",
      "Finished True Ashoka- Saraca asoca in Kerala during 2019 in 21.38287901878357 seconds\n",
      "102/924 observations invalid in Wood Apple- Aegle marmelos in 2019 in Kerala\n",
      "Finished Wood Apple- Aegle marmelos in Kerala during 2019 in 21.241792917251587 seconds\n",
      "Finished Kerala during 2019 in 471.8773601055145 seconds\n",
      "**********2020**********\n",
      "136/1564 observations invalid in Amla- Phyllanthus emblica in 2020 in Kerala\n",
      "Finished Amla- Phyllanthus emblica in Kerala during 2020 in 21.272722482681274 seconds\n",
      "93/1023 observations invalid in Coconut palm-Cocos nucifera in 2020 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2020 in 14.596266031265259 seconds\n",
      "75/821 observations invalid in Guava tree-Psidium guajava in 2020 in Kerala\n",
      "Finished Guava tree-Psidium guajava in Kerala during 2020 in 12.926778554916382 seconds\n",
      "78/842 observations invalid in Gulmohur- Delonix regia in 2020 in Kerala\n",
      "Finished Gulmohur- Delonix regia in Kerala during 2020 in 21.106981992721558 seconds\n",
      "184/2138 observations invalid in Indian laburnum- Cassia fistula in 2020 in Kerala\n",
      "Finished Indian laburnum- Cassia fistula in Kerala during 2020 in 21.498615980148315 seconds\n",
      "610/7460 observations invalid in Jackfruit- Artocarpus heterophyllus in 2020 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2020 in 22.10450506210327 seconds\n",
      "134/1446 observations invalid in Jamun- Syzygium cumini in 2020 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2020 in 21.239115238189697 seconds\n",
      "712/8797 observations invalid in Mango (all varieties)- Mangifera indica in 2020 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2020 in 22.429076671600342 seconds\n",
      "130/1412 observations invalid in Maulsari- Mimusops elengi in 2020 in Kerala\n",
      "Finished Maulsari- Mimusops elengi in Kerala during 2020 in 21.222900390625 seconds\n",
      "80/842 observations invalid in Neem- Azadirachta indica in 2020 in Kerala\n",
      "Finished Neem- Azadirachta indica in Kerala during 2020 in 15.444469213485718 seconds\n",
      "110/1159 observations invalid in Purple bauhinia- Bauhinia purpurea in 2020 in Kerala\n",
      "Finished Purple bauhinia- Bauhinia purpurea in Kerala during 2020 in 21.280561208724976 seconds\n",
      "81/972 observations invalid in Rain tree-Samanea saman in 2020 in Kerala\n",
      "Finished Rain tree-Samanea saman in Kerala during 2020 in 21.204065799713135 seconds\n",
      "241/2839 observations invalid in Tamarind- Tamarindus indica in 2020 in Kerala\n",
      "Finished Tamarind- Tamarindus indica in Kerala during 2020 in 21.667393445968628 seconds\n",
      "Finished Kerala during 2020 in 258.2591915130615 seconds\n",
      "**********2021**********\n",
      "122/1452 observations invalid in Amla- Phyllanthus emblica in 2021 in Kerala\n",
      "Finished Amla- Phyllanthus emblica in Kerala during 2021 in 16.521437644958496 seconds\n",
      "76/785 observations invalid in Coconut palm-Cocos nucifera in 2021 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2021 in 16.818887948989868 seconds\n",
      "101/1059 observations invalid in Guava tree-Psidium guajava in 2021 in Kerala\n",
      "Finished Guava tree-Psidium guajava in Kerala during 2021 in 18.63453245162964 seconds\n",
      "79/842 observations invalid in Gulmohur- Delonix regia in 2021 in Kerala\n",
      "Finished Gulmohur- Delonix regia in Kerala during 2021 in 15.919195413589478 seconds\n",
      "169/1995 observations invalid in Indian laburnum- Cassia fistula in 2021 in Kerala\n",
      "Finished Indian laburnum- Cassia fistula in Kerala during 2021 in 17.158609867095947 seconds\n",
      "516/6243 observations invalid in Jackfruit- Artocarpus heterophyllus in 2021 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2021 in 20.318671464920044 seconds\n",
      "111/1263 observations invalid in Jamun- Syzygium cumini in 2021 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2021 in 16.8328914642334 seconds\n",
      "646/7841 observations invalid in Mango (all varieties)- Mangifera indica in 2021 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2021 in 20.66121554374695 seconds\n",
      "95/1044 observations invalid in Maulsari- Mimusops elengi in 2021 in Kerala\n",
      "Finished Maulsari- Mimusops elengi in Kerala during 2021 in 15.972014904022217 seconds\n",
      "90/999 observations invalid in Purple bauhinia- Bauhinia purpurea in 2021 in Kerala\n",
      "Finished Purple bauhinia- Bauhinia purpurea in Kerala during 2021 in 17.688072681427002 seconds\n",
      "77/905 observations invalid in Rain tree-Samanea saman in 2021 in Kerala\n",
      "Finished Rain tree-Samanea saman in Kerala during 2021 in 15.565358638763428 seconds\n",
      "214/2545 observations invalid in Tamarind- Tamarindus indica in 2021 in Kerala\n",
      "Finished Tamarind- Tamarindus indica in Kerala during 2021 in 18.45914077758789 seconds\n",
      "81/816 observations invalid in Teak- Tectona grandis in 2021 in Kerala\n",
      "Finished Teak- Tectona grandis in Kerala during 2021 in 16.368740797042847 seconds\n",
      "Finished Kerala during 2021 in 227.1568465232849 seconds\n",
      "**********2022**********\n",
      "150/1667 observations invalid in Amla- Phyllanthus emblica in 2022 in Kerala\n",
      "Finished Amla- Phyllanthus emblica in Kerala during 2022 in 21.44376301765442 seconds\n",
      "103/1009 observations invalid in Chiku- Sapodilla-Manilkara zapota  in 2022 in Kerala\n",
      "Finished Chiku- Sapodilla-Manilkara zapota  in Kerala during 2022 in 21.284001111984253 seconds\n",
      "172/1956 observations invalid in Coconut palm-Cocos nucifera in 2022 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2022 in 21.521488189697266 seconds\n",
      "177/1977 observations invalid in Guava tree-Psidium guajava in 2022 in Kerala\n",
      "Finished Guava tree-Psidium guajava in Kerala during 2022 in 21.49309730529785 seconds\n",
      "116/1247 observations invalid in Gulmohur- Delonix regia in 2022 in Kerala\n",
      "Finished Gulmohur- Delonix regia in Kerala during 2022 in 21.403350114822388 seconds\n",
      "226/2702 observations invalid in Indian laburnum- Cassia fistula in 2022 in Kerala\n",
      "Finished Indian laburnum- Cassia fistula in Kerala during 2022 in 21.71274757385254 seconds\n",
      "715/8692 observations invalid in Jackfruit- Artocarpus heterophyllus in 2022 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2022 in 22.590100049972534 seconds\n",
      "149/1595 observations invalid in Jamun- Syzygium cumini in 2022 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2022 in 21.350273847579956 seconds\n",
      "718/8803 observations invalid in Mango (all varieties)- Mangifera indica in 2022 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2022 in 22.675867557525635 seconds\n",
      "130/1393 observations invalid in Maulsari- Mimusops elengi in 2022 in Kerala\n",
      "Finished Maulsari- Mimusops elengi in Kerala during 2022 in 21.329299926757812 seconds\n",
      "141/1541 observations invalid in Neem- Azadirachta indica in 2022 in Kerala\n",
      "Finished Neem- Azadirachta indica in Kerala during 2022 in 21.36607050895691 seconds\n",
      "117/1183 observations invalid in Peepal- Ficus religiosa in 2022 in Kerala\n",
      "Finished Peepal- Ficus religiosa in Kerala during 2022 in 21.309898376464844 seconds\n",
      "114/1223 observations invalid in Purple bauhinia- Bauhinia purpurea in 2022 in Kerala\n",
      "Finished Purple bauhinia- Bauhinia purpurea in Kerala during 2022 in 21.34117841720581 seconds\n",
      "146/1584 observations invalid in Rain tree-Samanea saman in 2022 in Kerala\n",
      "Finished Rain tree-Samanea saman in Kerala during 2022 in 21.367539644241333 seconds\n",
      "255/2935 observations invalid in Tamarind- Tamarindus indica in 2022 in Kerala\n",
      "Finished Tamarind- Tamarindus indica in Kerala during 2022 in 21.700828552246094 seconds\n",
      "95/981 observations invalid in Teak- Tectona grandis in 2022 in Kerala\n",
      "Finished Teak- Tectona grandis in Kerala during 2022 in 21.270159244537354 seconds\n",
      "99/1036 observations invalid in True Ashoka- Saraca asoca in 2022 in Kerala\n",
      "Finished True Ashoka- Saraca asoca in Kerala during 2022 in 21.293598651885986 seconds\n",
      "98/881 observations invalid in Wood Apple- Aegle marmelos in 2022 in Kerala\n",
      "Finished Wood Apple- Aegle marmelos in Kerala during 2022 in 21.27888321876526 seconds\n",
      "Finished Kerala during 2022 in 388.1384973526001 seconds\n",
      "**********2023**********\n",
      "89/909 observations invalid in Amla- Phyllanthus emblica in 2023 in Kerala\n",
      "Finished Amla- Phyllanthus emblica in Kerala during 2023 in 21.209184169769287 seconds\n",
      "102/1059 observations invalid in Chiku- Sapodilla-Manilkara zapota  in 2023 in Kerala\n",
      "Finished Chiku- Sapodilla-Manilkara zapota  in Kerala during 2023 in 21.3049156665802 seconds\n",
      "254/2912 observations invalid in Coconut palm-Cocos nucifera in 2023 in Kerala\n",
      "Finished Coconut palm-Cocos nucifera in Kerala during 2023 in 21.722904443740845 seconds\n",
      "93/982 observations invalid in Curry leaf plant-Murraya koenigii in 2023 in Kerala\n",
      "Finished Curry leaf plant-Murraya koenigii in Kerala during 2023 in 21.265345573425293 seconds\n",
      "89/902 observations invalid in Custard apple-Annona squamosa in 2023 in Kerala\n",
      "Finished Custard apple-Annona squamosa in Kerala during 2023 in 21.25618600845337 seconds\n",
      "145/1552 observations invalid in Drumstick tree-Moringa oleifera in 2023 in Kerala\n",
      "Finished Drumstick tree-Moringa oleifera in Kerala during 2023 in 21.31544589996338 seconds\n",
      "174/1941 observations invalid in Guava tree-Psidium guajava in 2023 in Kerala\n",
      "Finished Guava tree-Psidium guajava in Kerala during 2023 in 21.515377283096313 seconds\n",
      "101/997 observations invalid in Gulmohur- Delonix regia in 2023 in Kerala\n",
      "Finished Gulmohur- Delonix regia in Kerala during 2023 in 21.269673109054565 seconds\n",
      "93/981 observations invalid in Indian Almond- Terminalia catappa in 2023 in Kerala\n",
      "Finished Indian Almond- Terminalia catappa in Kerala during 2023 in 21.212697505950928 seconds\n",
      "188/2186 observations invalid in Indian laburnum- Cassia fistula in 2023 in Kerala\n",
      "Finished Indian laburnum- Cassia fistula in Kerala during 2023 in 21.55246138572693 seconds\n",
      "506/6147 observations invalid in Jackfruit- Artocarpus heterophyllus in 2023 in Kerala\n",
      "Finished Jackfruit- Artocarpus heterophyllus in Kerala during 2023 in 22.185842275619507 seconds\n",
      "87/802 observations invalid in Jamun- Syzygium cumini in 2023 in Kerala\n",
      "Finished Jamun- Syzygium cumini in Kerala during 2023 in 21.18924045562744 seconds\n",
      "547/6620 observations invalid in Mango (all varieties)- Mangifera indica in 2023 in Kerala\n",
      "Finished Mango (all varieties)- Mangifera indica in Kerala during 2023 in 22.383307933807373 seconds\n",
      "181/2047 observations invalid in Neem- Azadirachta indica in 2023 in Kerala\n",
      "Finished Neem- Azadirachta indica in Kerala during 2023 in 21.521151065826416 seconds\n",
      "84/811 observations invalid in Peepal- Ficus religiosa in 2023 in Kerala\n",
      "Finished Peepal- Ficus religiosa in Kerala during 2023 in 21.2143976688385 seconds\n",
      "112/1156 observations invalid in Purple bauhinia- Bauhinia purpurea in 2023 in Kerala\n",
      "Finished Purple bauhinia- Bauhinia purpurea in Kerala during 2023 in 21.234305143356323 seconds\n",
      "141/1557 observations invalid in Rain tree-Samanea saman in 2023 in Kerala\n",
      "Finished Rain tree-Samanea saman in Kerala during 2023 in 21.41855001449585 seconds\n",
      "166/1822 observations invalid in Tamarind- Tamarindus indica in 2023 in Kerala\n",
      "Finished Tamarind- Tamarindus indica in Kerala during 2023 in 21.509233713150024 seconds\n",
      "95/963 observations invalid in Teak- Tectona grandis in 2023 in Kerala\n",
      "Finished Teak- Tectona grandis in Kerala during 2023 in 21.262224912643433 seconds\n",
      "91/826 observations invalid in Wood Apple- Aegle marmelos in 2023 in Kerala\n",
      "Finished Wood Apple- Aegle marmelos in Kerala during 2023 in 21.21489667892456 seconds\n",
      "Finished Kerala during 2023 in 429.15036368370056 seconds\n",
      "Finished Kerala in 1881.8927714824677 seconds\n",
      "**********Karnataka**********\n",
      "**********2018**********\n",
      "Finished Karnataka during 2018 in 0.019156217575073242 seconds\n",
      "**********2019**********\n",
      "Finished Karnataka during 2019 in 0.024284839630126953 seconds\n",
      "**********2020**********\n",
      "Finished Karnataka during 2020 in 0.009705066680908203 seconds\n",
      "**********2021**********\n",
      "Finished Karnataka during 2021 in 0.011347055435180664 seconds\n",
      "**********2022**********\n",
      "Finished Karnataka during 2022 in 0.020776987075805664 seconds\n",
      "**********2023**********\n",
      "74/831 observations invalid in Gulmohur- Delonix regia in 2023 in Karnataka\n",
      "Finished Gulmohur- Delonix regia in Karnataka during 2023 in 18.407429218292236 seconds\n",
      "Finished Karnataka during 2023 in 18.4444477558136 seconds\n",
      "Finished Karnataka in 18.54861354827881 seconds\n",
      "**********Telangana**********\n",
      "**********2018**********\n",
      "Finished Telangana during 2018 in 0.0030150413513183594 seconds\n",
      "**********2019**********\n",
      "Finished Telangana during 2019 in 0.006390571594238281 seconds\n",
      "**********2020**********\n",
      "Finished Telangana during 2020 in 0.0008480548858642578 seconds\n",
      "**********2021**********\n",
      "Finished Telangana during 2021 in 0.002434253692626953 seconds\n",
      "**********2022**********\n",
      "Finished Telangana during 2022 in 0.02002692222595215 seconds\n",
      "**********2023**********\n",
      "Finished Telangana during 2023 in 0.018746614456176758 seconds\n",
      "Finished Telangana in 0.06787347793579102 seconds\n",
      "**********Puducherry**********\n",
      "**********2019**********\n",
      "Finished Puducherry during 2019 in 0.010046005249023438 seconds\n",
      "**********2020**********\n",
      "Finished Puducherry during 2020 in 0.009376049041748047 seconds\n",
      "**********2021**********\n",
      "Finished Puducherry during 2021 in 0.010057449340820312 seconds\n",
      "**********2022**********\n",
      "Finished Puducherry during 2022 in 0.015767812728881836 seconds\n",
      "**********2023**********\n",
      "Finished Puducherry during 2023 in 0.012160062789916992 seconds\n",
      "Finished Puducherry in 0.07381343841552734 seconds\n",
      "**********Maharashtra**********\n",
      "**********2018**********\n",
      "Finished Maharashtra during 2018 in 0.015387773513793945 seconds\n",
      "**********2019**********\n",
      "Finished Maharashtra during 2019 in 0.02236652374267578 seconds\n",
      "**********2020**********\n",
      "Finished Maharashtra during 2020 in 0.005158185958862305 seconds\n",
      "**********2021**********\n",
      "Finished Maharashtra during 2021 in 0.011548757553100586 seconds\n",
      "**********2022**********\n",
      "Finished Maharashtra during 2022 in 0.03149914741516113 seconds\n",
      "**********2023**********\n",
      "Finished Maharashtra during 2023 in 0.0380101203918457 seconds\n",
      "Finished Maharashtra in 0.14166975021362305 seconds\n",
      "**********Tamil Nadu**********\n",
      "**********2018**********\n",
      "Finished Tamil Nadu during 2018 in 0.008451700210571289 seconds\n",
      "**********2019**********\n",
      "Finished Tamil Nadu during 2019 in 0.029923677444458008 seconds\n",
      "**********2020**********\n",
      "Finished Tamil Nadu during 2020 in 0.018659353256225586 seconds\n",
      "**********2021**********\n",
      "Finished Tamil Nadu during 2021 in 0.016729116439819336 seconds\n",
      "**********2022**********\n",
      "Finished Tamil Nadu during 2022 in 0.026552915573120117 seconds\n",
      "**********2023**********\n",
      "Finished Tamil Nadu during 2023 in 0.05111837387084961 seconds\n",
      "Finished Tamil Nadu in 0.1695389747619629 seconds\n",
      "**********Goa**********\n",
      "**********2018**********\n",
      "Finished Goa during 2018 in 0.009678840637207031 seconds\n",
      "**********2019**********\n",
      "Finished Goa during 2019 in 0.015438318252563477 seconds\n",
      "**********2020**********\n",
      "Finished Goa during 2020 in 0.0024814605712890625 seconds\n",
      "**********2021**********\n",
      "Finished Goa during 2021 in 0.005645751953125 seconds\n",
      "**********2022**********\n",
      "Finished Goa during 2022 in 0.0017695426940917969 seconds\n",
      "**********2023**********\n",
      "Finished Goa during 2023 in 0.008106470108032227 seconds\n",
      "Finished Goa in 0.05975699424743652 seconds\n",
      "**********Odisha**********\n",
      "**********2018**********\n",
      "Finished Odisha during 2018 in 0.000896453857421875 seconds\n",
      "**********2019**********\n",
      "Finished Odisha during 2019 in 0.010568857192993164 seconds\n",
      "**********2020**********\n",
      "Finished Odisha during 2020 in 0.0050966739654541016 seconds\n",
      "**********2021**********\n",
      "Finished Odisha during 2021 in 0.003551483154296875 seconds\n",
      "**********2022**********\n",
      "Finished Odisha during 2022 in 0.013607025146484375 seconds\n",
      "**********2023**********\n",
      "Finished Odisha during 2023 in 0.010134696960449219 seconds\n",
      "Finished Odisha in 0.061225175857543945 seconds\n",
      "**********Manipur**********\n",
      "**********2018**********\n",
      "Finished Manipur during 2018 in 0.004342555999755859 seconds\n",
      "**********2022**********\n",
      "Finished Manipur during 2022 in 0.008187294006347656 seconds\n",
      "**********2023**********\n",
      "Finished Manipur during 2023 in 0.0008625984191894531 seconds\n",
      "Finished Manipur in 0.029031753540039062 seconds\n",
      "**********Andhra Pradesh**********\n",
      "**********2018**********\n",
      "Finished Andhra Pradesh during 2018 in 0.008792877197265625 seconds\n",
      "**********2019**********\n",
      "Finished Andhra Pradesh during 2019 in 0.009824514389038086 seconds\n",
      "**********2020**********\n",
      "Finished Andhra Pradesh during 2020 in 0.0006263256072998047 seconds\n",
      "**********2021**********\n",
      "Finished Andhra Pradesh during 2021 in 0.0005917549133300781 seconds\n",
      "**********2022**********\n",
      "Finished Andhra Pradesh during 2022 in 0.004106044769287109 seconds\n",
      "**********2023**********\n",
      "Finished Andhra Pradesh during 2023 in 0.005063056945800781 seconds\n",
      "Finished Andhra Pradesh in 0.04559659957885742 seconds\n",
      "**********Rajasthan**********\n",
      "**********2018**********\n",
      "Finished Rajasthan during 2018 in 0.00675201416015625 seconds\n",
      "**********2019**********\n",
      "Finished Rajasthan during 2019 in 0.00933384895324707 seconds\n",
      "**********2020**********\n",
      "Finished Rajasthan during 2020 in 0.004101991653442383 seconds\n",
      "**********2021**********\n",
      "Finished Rajasthan during 2021 in 0.008157730102539062 seconds\n",
      "**********2022**********\n",
      "Finished Rajasthan during 2022 in 0.012987136840820312 seconds\n",
      "**********2023**********\n",
      "Finished Rajasthan during 2023 in 0.01853179931640625 seconds\n",
      "Finished Rajasthan in 0.07587885856628418 seconds\n",
      "**********West Bengal**********\n",
      "**********2018**********\n",
      "Finished West Bengal during 2018 in 0.01680588722229004 seconds\n",
      "**********2019**********\n",
      "Finished West Bengal during 2019 in 0.013264894485473633 seconds\n",
      "**********2020**********\n",
      "Finished West Bengal during 2020 in 0.001310586929321289 seconds\n",
      "**********2021**********\n",
      "Finished West Bengal during 2021 in 0.0015294551849365234 seconds\n",
      "**********2022**********\n",
      "Finished West Bengal during 2022 in 0.0074198246002197266 seconds\n",
      "**********2023**********\n",
      "Finished West Bengal during 2023 in 0.014693260192871094 seconds\n",
      "Finished West Bengal in 0.07128787040710449 seconds\n",
      "**********Chhattisgarh**********\n",
      "**********2018**********\n",
      "Finished Chhattisgarh during 2018 in 0.003845691680908203 seconds\n",
      "**********2019**********\n",
      "Finished Chhattisgarh during 2019 in 0.005989789962768555 seconds\n",
      "**********2020**********\n",
      "Finished Chhattisgarh during 2020 in 0.001348733901977539 seconds\n",
      "**********2021**********\n",
      "Finished Chhattisgarh during 2021 in 0.0008599758148193359 seconds\n",
      "**********2022**********\n",
      "Finished Chhattisgarh during 2022 in 0.0034983158111572266 seconds\n",
      "**********2023**********\n",
      "Finished Chhattisgarh during 2023 in 0.007771730422973633 seconds\n",
      "Finished Chhattisgarh in 0.039153099060058594 seconds\n",
      "**********Madhya Pradesh**********\n",
      "**********2018**********\n",
      "Finished Madhya Pradesh during 2018 in 0.007344961166381836 seconds\n",
      "**********2019**********\n",
      "Finished Madhya Pradesh during 2019 in 0.012660980224609375 seconds\n",
      "**********2020**********\n",
      "Finished Madhya Pradesh during 2020 in 0.010309219360351562 seconds\n",
      "**********2021**********\n",
      "Finished Madhya Pradesh during 2021 in 0.012807607650756836 seconds\n",
      "**********2022**********\n",
      "Finished Madhya Pradesh during 2022 in 0.02270650863647461 seconds\n",
      "**********2023**********\n",
      "Finished Madhya Pradesh during 2023 in 0.03198695182800293 seconds\n",
      "Finished Madhya Pradesh in 0.11553359031677246 seconds\n",
      "**********Punjab**********\n",
      "**********2018**********\n",
      "Finished Punjab during 2018 in 0.0011126995086669922 seconds\n",
      "**********2019**********\n",
      "Finished Punjab during 2019 in 0.0012917518615722656 seconds\n",
      "**********2020**********\n",
      "Finished Punjab during 2020 in 0.0005538463592529297 seconds\n",
      "**********2021**********\n",
      "Finished Punjab during 2021 in 0.0010869503021240234 seconds\n",
      "**********2022**********\n",
      "Finished Punjab during 2022 in 0.003383159637451172 seconds\n",
      "**********2023**********\n",
      "Finished Punjab during 2023 in 0.0017309188842773438 seconds\n",
      "Finished Punjab in 0.026058197021484375 seconds\n",
      "**********Gujarat**********\n",
      "**********2018**********\n",
      "Finished Gujarat during 2018 in 0.0017910003662109375 seconds\n",
      "**********2019**********\n",
      "Finished Gujarat during 2019 in 0.0015234947204589844 seconds\n",
      "**********2020**********\n",
      "Finished Gujarat during 2020 in 0.002454519271850586 seconds\n",
      "**********2021**********\n",
      "Finished Gujarat during 2021 in 0.0029435157775878906 seconds\n",
      "**********2022**********\n",
      "Finished Gujarat during 2022 in 0.008113622665405273 seconds\n",
      "**********2023**********\n",
      "Finished Gujarat during 2023 in 0.013400554656982422 seconds\n",
      "Finished Gujarat in 0.04627633094787598 seconds\n",
      "**********Andaman and Nicobar Islands**********\n",
      "**********2019**********\n",
      "Finished Andaman and Nicobar Islands during 2019 in 0.0031769275665283203 seconds\n",
      "**********2021**********\n",
      "Finished Andaman and Nicobar Islands during 2021 in 0.0025224685668945312 seconds\n",
      "**********2022**********\n",
      "Finished Andaman and Nicobar Islands during 2022 in 0.01533198356628418 seconds\n",
      "**********2023**********\n",
      "Finished Andaman and Nicobar Islands during 2023 in 0.013024568557739258 seconds\n",
      "Finished Andaman and Nicobar Islands in 0.05070066452026367 seconds\n",
      "**********Uttar Pradesh**********\n",
      "**********2019**********\n",
      "Finished Uttar Pradesh during 2019 in 0.00506281852722168 seconds\n",
      "**********2020**********\n",
      "Finished Uttar Pradesh during 2020 in 0.001976490020751953 seconds\n",
      "**********2021**********\n",
      "Finished Uttar Pradesh during 2021 in 0.0033729076385498047 seconds\n",
      "**********2022**********\n",
      "Finished Uttar Pradesh during 2022 in 0.0044078826904296875 seconds\n",
      "**********2023**********\n",
      "Finished Uttar Pradesh during 2023 in 0.007692098617553711 seconds\n",
      "Finished Uttar Pradesh in 0.03839683532714844 seconds\n",
      "**********Uttarakhand**********\n",
      "**********2018**********\n",
      "Finished Uttarakhand during 2018 in 0.010223150253295898 seconds\n",
      "**********2019**********\n",
      "Finished Uttarakhand during 2019 in 0.015296220779418945 seconds\n",
      "**********2020**********\n",
      "Finished Uttarakhand during 2020 in 0.0013041496276855469 seconds\n",
      "**********2021**********\n",
      "Finished Uttarakhand during 2021 in 0.001758575439453125 seconds\n",
      "**********2022**********\n",
      "Finished Uttarakhand during 2022 in 0.008267879486083984 seconds\n",
      "**********2023**********\n",
      "Finished Uttarakhand during 2023 in 0.0057909488677978516 seconds\n",
      "Finished Uttarakhand in 0.058927059173583984 seconds\n",
      "**********Assam**********\n",
      "**********2018**********\n",
      "Finished Assam during 2018 in 0.0017979145050048828 seconds\n",
      "**********2019**********\n",
      "Finished Assam during 2019 in 0.006655693054199219 seconds\n",
      "**********2020**********\n",
      "Finished Assam during 2020 in 0.0005583763122558594 seconds\n",
      "**********2021**********\n",
      "Finished Assam during 2021 in 0.0036106109619140625 seconds\n",
      "**********2022**********\n",
      "Finished Assam during 2022 in 0.008055686950683594 seconds\n",
      "**********2023**********\n",
      "Finished Assam during 2023 in 0.007172346115112305 seconds\n",
      "Finished Assam in 0.043692827224731445 seconds\n",
      "**********Meghalaya**********\n",
      "**********2018**********\n",
      "Finished Meghalaya during 2018 in 0.00467228889465332 seconds\n",
      "**********2019**********\n",
      "Finished Meghalaya during 2019 in 0.018834590911865234 seconds\n",
      "**********2020**********\n",
      "Finished Meghalaya during 2020 in 0.003225564956665039 seconds\n",
      "**********2021**********\n",
      "Finished Meghalaya during 2021 in 0.0031592845916748047 seconds\n",
      "**********2022**********\n",
      "Finished Meghalaya during 2022 in 0.003426790237426758 seconds\n",
      "**********2023**********\n",
      "Finished Meghalaya during 2023 in 0.0015566349029541016 seconds\n",
      "Finished Meghalaya in 0.05093097686767578 seconds\n",
      "**********Nagaland**********\n",
      "**********2021**********\n",
      "Finished Nagaland during 2021 in 0.0010924339294433594 seconds\n",
      "**********2022**********\n",
      "Finished Nagaland during 2022 in 0.006313323974609375 seconds\n",
      "**********2023**********\n",
      "Finished Nagaland during 2023 in 0.0039103031158447266 seconds\n",
      "Finished Nagaland in 0.02703237533569336 seconds\n",
      "**********Tripura**********\n",
      "**********2018**********\n",
      "Finished Tripura during 2018 in 0.00429224967956543 seconds\n",
      "Finished Tripura in 0.019858360290527344 seconds\n",
      "**********Delhi**********\n",
      "**********2019**********\n",
      "Finished Delhi during 2019 in 0.0057146549224853516 seconds\n",
      "**********2020**********\n",
      "Finished Delhi during 2020 in 0.004271984100341797 seconds\n",
      "**********2021**********\n",
      "Finished Delhi during 2021 in 0.0026645660400390625 seconds\n",
      "**********2022**********\n",
      "Finished Delhi during 2022 in 0.00536656379699707 seconds\n",
      "**********2023**********\n",
      "Finished Delhi during 2023 in 0.00741887092590332 seconds\n",
      "Finished Delhi in 0.04117012023925781 seconds\n",
      "**********Jammu and Kashmir**********\n",
      "**********2019**********\n",
      "Finished Jammu and Kashmir during 2019 in 0.0010917186737060547 seconds\n",
      "**********2022**********\n",
      "Finished Jammu and Kashmir during 2022 in 0.0005466938018798828 seconds\n",
      "**********2023**********\n",
      "Finished Jammu and Kashmir during 2023 in 0.0017740726470947266 seconds\n",
      "Finished Jammu and Kashmir in 0.01902151107788086 seconds\n",
      "**********Himachal Pradesh**********\n",
      "**********2018**********\n",
      "Finished Himachal Pradesh during 2018 in 0.0005819797515869141 seconds\n",
      "**********2019**********\n",
      "Finished Himachal Pradesh during 2019 in 0.0017943382263183594 seconds\n",
      "**********2020**********\n",
      "Finished Himachal Pradesh during 2020 in 0.0008428096771240234 seconds\n",
      "**********2021**********\n",
      "Finished Himachal Pradesh during 2021 in 0.0038428306579589844 seconds\n",
      "**********2022**********\n",
      "Finished Himachal Pradesh during 2022 in 0.0010843276977539062 seconds\n",
      "**********2023**********\n",
      "Finished Himachal Pradesh during 2023 in 0.0015323162078857422 seconds\n",
      "Finished Himachal Pradesh in 0.025365114212036133 seconds\n",
      "**********Jharkhand**********\n",
      "**********2018**********\n",
      "Finished Jharkhand during 2018 in 0.0020105838775634766 seconds\n",
      "**********2019**********\n",
      "Finished Jharkhand during 2019 in 0.0040493011474609375 seconds\n",
      "**********2020**********\n",
      "Finished Jharkhand during 2020 in 0.0005419254302978516 seconds\n",
      "**********2021**********\n",
      "Finished Jharkhand during 2021 in 0.0015578269958496094 seconds\n",
      "**********2022**********\n",
      "Finished Jharkhand during 2022 in 0.002683401107788086 seconds\n",
      "**********2023**********\n",
      "Finished Jharkhand during 2023 in 0.0028841495513916016 seconds\n",
      "Finished Jharkhand in 0.02947854995727539 seconds\n",
      "**********Haryana**********\n",
      "**********2018**********\n",
      "Finished Haryana during 2018 in 0.0022325515747070312 seconds\n",
      "**********2019**********\n",
      "Finished Haryana during 2019 in 0.0012929439544677734 seconds\n",
      "**********2020**********\n",
      "Finished Haryana during 2020 in 0.0005450248718261719 seconds\n",
      "**********2021**********\n",
      "Finished Haryana during 2021 in 0.0018429756164550781 seconds\n",
      "**********2022**********\n",
      "Finished Haryana during 2022 in 0.0020236968994140625 seconds\n",
      "**********2023**********\n",
      "Finished Haryana during 2023 in 0.001766204833984375 seconds\n",
      "Finished Haryana in 0.02543187141418457 seconds\n",
      "**********Arunachal Pradesh**********\n",
      "**********2019**********\n",
      "Finished Arunachal Pradesh during 2019 in 0.0009760856628417969 seconds\n",
      "**********2023**********\n",
      "Finished Arunachal Pradesh during 2023 in 0.003515958786010742 seconds\n",
      "Finished Arunachal Pradesh in 0.02052474021911621 seconds\n",
      "**********Bihar**********\n",
      "**********2019**********\n",
      "Finished Bihar during 2019 in 0.0008673667907714844 seconds\n",
      "**********2020**********\n",
      "Finished Bihar during 2020 in 0.0012860298156738281 seconds\n",
      "**********2021**********\n",
      "Finished Bihar during 2021 in 0.0019953250885009766 seconds\n",
      "**********2022**********\n",
      "Finished Bihar during 2022 in 0.0008351802825927734 seconds\n",
      "**********2023**********\n",
      "Finished Bihar during 2023 in 0.00220489501953125 seconds\n",
      "Finished Bihar in 0.022835731506347656 seconds\n",
      "**********Lakshadweep**********\n",
      "**********2018**********\n",
      "Finished Lakshadweep during 2018 in 0.0004417896270751953 seconds\n",
      "Finished Lakshadweep in 0.016202926635742188 seconds\n",
      "**********Sikkim**********\n",
      "**********2019**********\n",
      "Finished Sikkim during 2019 in 0.001096963882446289 seconds\n",
      "**********2020**********\n",
      "Finished Sikkim during 2020 in 0.0005440711975097656 seconds\n",
      "**********2021**********\n",
      "Finished Sikkim during 2021 in 0.0008537769317626953 seconds\n",
      "**********2023**********\n",
      "Finished Sikkim during 2023 in 0.0008282661437988281 seconds\n",
      "Finished Sikkim in 0.020058155059814453 seconds\n",
      "**********Chandigarh**********\n",
      "**********2022**********\n",
      "Finished Chandigarh during 2022 in 0.0007927417755126953 seconds\n",
      "Finished Chandigarh in 0.016429662704467773 seconds\n",
      "**********Dadra and Nagar Haveli**********\n",
      "**********2019**********\n",
      "Finished Dadra and Nagar Haveli during 2019 in 0.0008604526519775391 seconds\n",
      "**********2020**********\n",
      "Finished Dadra and Nagar Haveli during 2020 in 0.0005402565002441406 seconds\n",
      "Finished Dadra and Nagar Haveli in 0.017014026641845703 seconds\n",
      "17625/335957 observations invalid overall\n",
      "Finished completely in 1902.0202581882477 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run anomaly detection on all citizen data and drop any anomalies\n",
    "invalid_indices = anomaly_detection_overall(df, 15*52) # Choose 15*52 as the min num of observations because it means there's an average of 15 observations per week\n",
    "df = df.drop(invalid_indices) # Drop observations deemed outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211c964",
   "metadata": {},
   "source": [
    "# Species ID <-> Name Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3ac7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species lookup dicts for id <-> name from species_codes.csv\n",
    "species_codes = pd.read_csv(\"species codes.csv\", encoding='unicode_escape')\n",
    "\n",
    "species_id_to_name = {}\n",
    "species_name_to_id = {}\n",
    "\n",
    "# Creating species id <-> name dictionaries\n",
    "# Refomatting species names from \"species codes.csv\" to match those of the citizen data\n",
    "# Load the reformatted data to dictionaries for converting species_name to species_id and vice versa\n",
    "for i, row in species_codes.iterrows():\n",
    "    species_id_to_name[row[\"species_id\"]] = \"{}-{}\".format(row[\"species_primary_common_name\"], row[\"species_scientific_name\"])\n",
    "    species_name_to_id[\"{}-{}\".format(row[\"species_primary_common_name\"], row[\"species_scientific_name\"]).lower().replace(\" \", \"\")] = row[\"species_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632e20f",
   "metadata": {},
   "source": [
    "# Encoding and Decoding Species ID & Species Names in Citizen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328d2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat species names in citizen data\n",
    "for i, row in df.iterrows():\n",
    "    name = row[\"Species_name\"].lower().replace(\" \", \"\") # Reformat species names\n",
    "\n",
    "    # Change formatting of species names within citizen observations to be standardized & consistent with reference data\n",
    "    if name == \"arjuntree-terminaliaarjuna\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1083]\n",
    "        continue\n",
    "    if name == \"axlewoodtree-anogeissuslatifolia\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1009]\n",
    "        continue\n",
    "    if name == \"chiku-sapodilla-manilkarazapota\\xa0\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1188]\n",
    "        continue\n",
    "    if name == \"dyer'soleander-wrightiatinctoria\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1181]\n",
    "        continue\n",
    "    if name == \"ficusmollis-softfig\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1197]\n",
    "        continue\n",
    "    if name == \"frangipani-templetree-plumeriarubra\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1176]\n",
    "        continue\n",
    "    if name == \"garuga-kharpat-garugapinnata\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1038]\n",
    "        continue\n",
    "    if name == \"ghostrree-sterculiaurens\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1078]\n",
    "        continue\n",
    "    if name == \"indianfrankincense-boswelliaserrata\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1195]\n",
    "        continue\n",
    "    if name == \"indiancoraltree-erythrinaindica\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1034]\n",
    "        continue\n",
    "    if name == \"kadamba-neolamarckiacadamba\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1058]\n",
    "        continue\n",
    "    if name == \"lanneacoromandelica-indianashtree\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1194]\n",
    "        continue\n",
    "    if name == \"mexicanoleander-yellowoleander-cascabelathevetia\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1177]\n",
    "        continue\n",
    "    if name == \"nightfloweringjasmine-harsingar-nyctanthesarbor-tristis\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1059]\n",
    "        continue\n",
    "    if name == \"prosopiscineraria-khejri\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1201]\n",
    "        continue\n",
    "    if name == \"raintree-samaneasaman\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1162]\n",
    "        continue\n",
    "    if name == \"redsilk-cotton-bombaxceiba\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1015]\n",
    "        continue\n",
    "    if name == \"whitesilk-cotton-ceibapentandra\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1021]\n",
    "        continue\n",
    "    if name == \"yellow-silkcottontree-cochlospermumreligiosum\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1023]\n",
    "        continue\n",
    "    if name == \"karkat-dogteak-dilleniapentagyna\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1032]\n",
    "        continue\n",
    "    if name == \"chosamango-mangiferaindica\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1108]\n",
    "        continue\n",
    "    if name == \"falsewhiteteak-mallotusnudiflorus\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1088]\n",
    "        continue\n",
    "    if name == \"floss-silktree-ceibaspeciosa\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1022]\n",
    "        continue\n",
    "    if name == \"largesebesten-bairola-cordiawallichii\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1026]\n",
    "        continue\n",
    "    if name == \"roxburghskydia-pulia-kydiacalycina\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1044]\n",
    "        continue\n",
    "    if name == \"wildrose-rosawebbiana\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1206]\n",
    "        continue\n",
    "    if name == \"albiziaodoratissima-blacksiris\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1199]\n",
    "        continue\n",
    "    if name == \"anogeissuspendula-kardhai\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1198]\n",
    "        continue\n",
    "    if name == \"brokenbonestree-oroxylumindicum\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = \"Broken Bones Tree-Oroxylum Indicum\"\n",
    "        continue\n",
    "    if name == \"pyinmatree-andamancrapemyrtle-lagerstroemiahypoleuca\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1216]\n",
    "        continue\n",
    "    if name == \"crataevareligiosa-garlic-peartree\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1196]\n",
    "        continue\n",
    "    if name == \"guh-de-three-leafcapertree-cratevaadansonii\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1217]\n",
    "        continue\n",
    "    if name == \"aabehayatmango-mangiferaindica\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1091]\n",
    "        continue\n",
    "    if name == \"bedu-punjabfig-ficuspalmata\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1235]\n",
    "        continue\n",
    "    if name == \"chinar-platanusorientalis\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = \"Chinar-Platanus Orientalis\"\n",
    "        continue\n",
    "    if name == \"prunusnepalensis-sohiong\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1192]\n",
    "        continue\n",
    "    if name == \"tecomellaundulata-roheda\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1200]\n",
    "        continue\n",
    "    if name == \"tigersmilkspruce-falconeriainsignis\": # If statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = \"Tiger's Milk Spruce-Falconeria Insignis\"\n",
    "        continue\n",
    "    if species_name_to_id[name]: # General case with no misspellings\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[species_name_to_id[name]] # species dictionaries to undo the .lower().replace(\" \",\"\") formatting\n",
    "\n",
    "# Adding a Species_id column to the citizen data for comparing to the reference database\n",
    "df.insert(loc = 4, column = 'Species_id', value = [species_name_to_id.get(species.lower().replace(\" \",\"\"), np.nan) for species in df[\"Species_name\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f4694",
   "metadata": {},
   "source": [
    "# Save Updated Citizen Data in One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740a837d-547c-46ea-bf0d-103ffcf9ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated_alldata.csv to disk\n",
    "df.to_csv('updated_alldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86773a",
   "metadata": {},
   "source": [
    "# Make Directories for Citizen and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd18c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for storing citizen and reference data.\n",
    "os.makedirs(\"all data/citizen\", exist_ok=True)\n",
    "os.makedirs(\"all data/reference\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa8a9e",
   "metadata": {},
   "source": [
    "# State DFs to all data/citizen folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861e6c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving separate CSV files for citizen observations based on state\n",
    "for state_name in df[\"State_name\"].unique(): # Iterate over all states\n",
    "    state_df = df[df[\"State_name\"] == state_name] # Only use observations from given state\n",
    "    state_df = state_df.drop([\"State_name\"], axis = 1) # Drop State_name column because it is the same value throughout each CSV file\n",
    "    state_name = state_name.replace(\" \",\"_\").lower() # Reformat state names to lowercase with _ instead of spaces\n",
    "    state_df.to_csv(f\"all data/citizen/{state_name}.csv\", index=False) # Save citizen observations in the given state to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb0ddd",
   "metadata": {},
   "source": [
    "# Reference Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "688529ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicts and Functions\n",
    "\n",
    "# Dictionary mapping reference data acronyms to citizen data phenophase names\n",
    "acronym_to_phenophase_dict = {'FL': 'Leaves_fresh', 'ML': 'Leaves_mature', 'DL': 'Leaves_old', \n",
    "                          'BD': 'Flowers_bud', 'OF': 'Flowers_open', 'MF': 'Flowers_male', \n",
    "                          'FF': 'Flowers_Female', 'UFR': 'Fruits_unripe', 'RFR': 'Fruits_ripe', \n",
    "                          'OFR': 'Fruits_open'} \n",
    "\n",
    "# Dictionary mapping reference data phenophase values (strings) to citizen data phenophase values (int or None)\n",
    "str_to_val_dict = {'NA': None, '': None, '0': 0, '1': 1, '2': 2} \n",
    "\n",
    "def split_reformat_code(code):\n",
    "    \"\"\"\n",
    "    Converts phenophase acronyms to phenophase names (e.g. 'FL' -> 'Leaves_fresh')\n",
    "\n",
    "    Args:\n",
    "        code (string): Phenophase acronym and value stored as one string\n",
    "    Returns:\n",
    "        code_attr_tup (tuple(string, int or None)): Phenophase acronym and value stored in tuple\n",
    "    \"\"\"\n",
    "    code_attr_tup = code.split('_') # Split code into acronym and value\n",
    "    code_attr_tup[0] = acronym_to_phenophase_dict[code_attr_tup[0]] # Phenophase acronym -> Phenophase name\n",
    "    code_attr_tup[1] = str_to_val_dict[code_attr_tup[1]] # Phenophase value (string) -> Phenophase value (int or None)\n",
    "    code_attr_tup = tuple(code_attr_tup) # Convert from list to tuple\n",
    "    return code_attr_tup\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    Cleans Reference Data:\n",
    "        Adds new columns: everything in df that is not a month, plus the 10 categorical codes, plus a 'week' column\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Reference data for a certain state\n",
    "    Returns:\n",
    "        new_df (DataFrame): Cleaned reference data for a certain state\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.drop_duplicates() # Drop reference data for species with duplicate yearly observations\n",
    "    \n",
    "    week_codes = [list(df.columns[3:-2]) # Names of week columns\n",
    "    base_cols = list(df.columns[:3]) + [df.columns[-1]] # Names of non-week columns excluding created_at (excluding this column acts as dropping it)\n",
    "    \n",
    "    new_cols = base_cols + ['week'] + list(acronym_to_phenophase_dict.values()) # Names of columns used in cleaned reference data\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=new_cols) # Initialize new DataFrame with the finalized columns\n",
    "\n",
    "    num_idxs = len(df) # Total number of indices of input reference data\n",
    "    \n",
    "    for idx, row in df.iterrows(): # Iterate over rows in input reference data\n",
    "                  \n",
    "        if idx % 10 == 0: # Every 10 iterations...\n",
    "            print(\"{} % done\".format(100 * idx / num_idxs)) # Progress update\n",
    "        \n",
    "        # Add records (rows) to the new DataFrame for each week (48 rows per species) with phenophases as columns\n",
    "        for week_idx, week_code in enumerate(week_codes): # Iterate over the 48 week columns\n",
    "            new_record = {} # Initialize new record to put into the new DataFrame\n",
    "            for old_colname in base_cols: # Iterate over non-week columns excluding created_at\n",
    "                new_record[old_colname] = row[old_colname] # Carry the values from the non-week columns over to the new DataFrame\n",
    "            new_record['week'] = week_idx # Add the associated week to the new record\n",
    "            phenophase_vals_for_week = row[week_code] # String of phenophase values for the associated week\n",
    "            # e.g. \"FL_NA,ML_NA,DL_NA,BD_NA,OF_NA,MF_NA,FF_NA,UFR_NA,RFR_NA,OFR_NA\"\n",
    "\n",
    "            # Add new record if phenophase values are all Null\n",
    "            if math.isnan(phenophase_vals_for_week): # If phenophase values is Null/NaN/None...\n",
    "                for phenophase in acronym_to_phenophase_dict.values(): # Iterate over phenophase names\n",
    "                    new_record[phenophase] = None # Add None as the phenophase values to the new record\n",
    "                new_df.loc[len(new_df)] = new_record # Add the new record to the new DataFrame\n",
    "            \n",
    "            # Add new record in typical case\n",
    "            else:\n",
    "                phenophase_val_list = list(map(split_reformat_code, phenophase_vals_for_week.split(\",\"))) # Phenophase names and their associated values\n",
    "                for (phenophase, value) in phenophase_val_list: # Iterate over phenophase names and values\n",
    "                    new_record[phenophase] = value # Add phenophase values to the new record\n",
    "\n",
    "                new_df.loc[len(new_df)] = new_record # Add the new record to the new DataFrame\n",
    "    \n",
    "    # Remove unnamed columns if they exist\n",
    "    for col in new_df.columns: # Iterate over all columns in the new DataFrame\n",
    "        if 'Unnamed' in col or col == 'id': # If given column is unnamed or the id column...\n",
    "            new_df = new_df.drop(col, axis=1) # Drop given column\n",
    "    \n",
    "    # Adding species_name column\n",
    "    new_df['species_name'] = new_df['species_id'].map(species_id_to_name) # Map species id to the associated species name\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe2b27",
   "metadata": {},
   "source": [
    "# Saving Cleaned Reference Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72c26c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning pvt_andaman_and_nicobar_islands.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_rajasthan.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "100.0 % done\n",
      "cleaning pvt_arunachal_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_madhya_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_assam.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_jharkhand.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_maharastra.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_karnataka.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_jammu_and_kashmir.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_pvt_haryana.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_manipur.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_delhi.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_tripura.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_odisha.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_tamil_nadu.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_gujarat.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_andhra_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_bihar.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_kerala.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_puducherry.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_meghalaya.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "# Clean all pvt tables & save them to disk in reference folder\n",
    "\n",
    "for tablename in os.listdir('./pvttables_raw/'): # Iterate through pvt tables\n",
    "    if tablename == '.DS_Store': # Ignore this file \n",
    "        continue\n",
    "    print(\"cleaning {}\".format(tablename))\n",
    "    ref_df = pd.read_csv('./pvttables_raw/{}'.format(tablename), sep=';') # Load the given pvt table\n",
    "    tablename = tablename.replace(\"pvt_\",\"\") # Reformat table name\n",
    "    if tablename == 'maharastra.csv': # Fix misspelling\n",
    "        tablename = 'maharashtra.csv'\n",
    "    new_df = clean_df(ref_df) # Clean reference data\n",
    "    new_df.to_csv('./all data/reference/{}'.format(tablename), index=False) # Save cleaned reference data to disk in reference folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
