{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14651e97",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba25580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/miniconda3/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: shapely in /opt/miniconda3/lib/python3.12/site-packages (2.0.4)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/miniconda3/lib/python3.12/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/miniconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.12/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/miniconda3/lib/python3.12/site-packages (from geopandas) (2.2.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (2024.6.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1609308f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point \n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9bffb",
   "metadata": {},
   "source": [
    "# Previewing Original Citizen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef76fac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Observation_ID</th>\n",
       "      <th>Date_of_observation</th>\n",
       "      <th>User_id</th>\n",
       "      <th>User_Tree_id</th>\n",
       "      <th>Species_name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Leaves_fresh</th>\n",
       "      <th>Leaves_mature</th>\n",
       "      <th>Leaves_old</th>\n",
       "      <th>Flowers_bud</th>\n",
       "      <th>Flowers_open</th>\n",
       "      <th>Flowers_male</th>\n",
       "      <th>Flowers_Female</th>\n",
       "      <th>Fruits_unripe</th>\n",
       "      <th>Fruits_ripe</th>\n",
       "      <th>Fruits_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>388564.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84299.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.15386</td>\n",
       "      <td>75.22397</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>388565.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84300.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.15386</td>\n",
       "      <td>75.22397</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>388566.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84301.0</td>\n",
       "      <td>Fish-tail palm- Caryota urens</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>388567.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84302.0</td>\n",
       "      <td>Mast Tree-Monoon longifolium</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>388568.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20396.0</td>\n",
       "      <td>84303.0</td>\n",
       "      <td>Indian Almond- Terminalia catappa</td>\n",
       "      <td>12.14060</td>\n",
       "      <td>75.22145</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Observation_ID Date_of_observation  User_id  User_Tree_id  \\\n",
       "0           1        388564.0          2020-01-01  20396.0       84299.0   \n",
       "1           2        388565.0          2020-01-01  20396.0       84300.0   \n",
       "2           3        388566.0          2020-01-01  20396.0       84301.0   \n",
       "3           4        388567.0          2020-01-01  20396.0       84302.0   \n",
       "4           5        388568.0          2020-01-01  20396.0       84303.0   \n",
       "\n",
       "                        Species_name       Lat      Long State_name  \\\n",
       "0  Indian Almond- Terminalia catappa  12.15386  75.22397     Kerala   \n",
       "1  Indian Almond- Terminalia catappa  12.15386  75.22397     Kerala   \n",
       "2      Fish-tail palm- Caryota urens  12.14060  75.22145     Kerala   \n",
       "3       Mast Tree-Monoon longifolium  12.14060  75.22145     Kerala   \n",
       "4  Indian Almond- Terminalia catappa  12.14060  75.22145     Kerala   \n",
       "\n",
       "   Leaves_fresh  Leaves_mature  Leaves_old  Flowers_bud  Flowers_open  \\\n",
       "0           2.0            0.0         0.0         -2.0          -2.0   \n",
       "1           2.0            0.0         0.0         -2.0          -2.0   \n",
       "2           0.0            2.0         0.0         -2.0          -2.0   \n",
       "3           1.0            2.0         0.0         -2.0          -2.0   \n",
       "4           0.0            1.0         2.0         -2.0          -2.0   \n",
       "\n",
       "   Flowers_male  Flowers_Female  Fruits_unripe  Fruits_ripe  Fruits_open  \n",
       "0          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "1          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "2          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "3          -2.0            -2.0           -2.0         -2.0         -2.0  \n",
       "4          -2.0            -2.0           -2.0         -2.0         -2.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"alldata.csv\")\n",
    "df.head() # Previewing alldata.csv before cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353169c4",
   "metadata": {},
   "source": [
    "# Handling Incorrect -2 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f5bb3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing incorrect -2 values with either NA or -2\n",
    "all_species = list(df['Species_name'].value_counts().index) # all species named in order of prevalence\n",
    "phenophases = list(df.columns[9:]) # Phenophases\n",
    "\n",
    "def create_species_dict(*absent_phenophases):\n",
    "    species_dict = dict(zip(phenophases, np.zeros(len(phenophases), int)))\n",
    "    for phenophase in absent_phenophases:\n",
    "        species_dict[phenophase] = 1\n",
    "    return species_dict\n",
    "\n",
    "handbook_dicts = {} # Dict mapping species to phenophase dicts. \n",
    "# phenophase dicts give absent phenophases in the associated species.\n",
    "# Manually input absent phenophases from SeasonWatch handbook\n",
    "handbook_dicts[all_species[0]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[1]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[2]] = create_species_dict('Flowers_open', 'Fruits_open')\n",
    "handbook_dicts[all_species[3]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[4]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[5]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[6]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[7]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[8]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[9]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[10]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[11]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[12]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[13]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[14]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[15]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[16]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[17]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[18]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[19]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[20]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[21]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[22]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[23]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[24]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[25]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[26]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[27]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[28]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[29]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[30]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[31]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[32]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[33]] = create_species_dict('Flowers_bud', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[34]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[35]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[36]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[37]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[38]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[39]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[40]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[41]] = create_species_dict('Flowers_open', 'Fruits_open')\n",
    "handbook_dicts[all_species[42]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[43]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[44]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[45]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[46]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[47]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[48]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[49]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[50]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[51]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[52]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[53]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[54]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[55]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[56]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[57]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[58]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[59]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[60]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[61]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[62]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[63]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[64]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[65]] = create_species_dict('Flowers_open', 'Fruits_open') # Silkworm Mulberry\n",
    "handbook_dicts[all_species[66]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[67]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[68]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[69]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[70]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[71]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[72]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[73]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[74]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[75]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[76]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[77]] = create_species_dict('Flowers_open', 'Fruits_open') # Box-myrtle\n",
    "handbook_dicts[all_species[78]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[79]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[80]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Airi Mango\n",
    "handbook_dicts[all_species[81]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[82]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[83]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[84]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[85]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[86]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[87]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[88]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[89]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[90]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[91]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[92]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[93]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[94]] = create_species_dict('Flowers_open') # Wild Almond\n",
    "handbook_dicts[all_species[95]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[96]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[97]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[98]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[99]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[100]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[101]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[102]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[103]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[104]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Alphonso Mango\n",
    "handbook_dicts[all_species[105]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[106]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[107]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[108]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[109]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[110]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[111]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[112]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[113]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[114]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[115]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Aabehayat Mango\n",
    "handbook_dicts[all_species[116]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[117]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[118]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[119]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[120]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[121]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[122]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[123]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[124]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[125]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[126]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[127]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[128]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[129]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Manjeera Mango\n",
    "handbook_dicts[all_species[130]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[131]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[132]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[133]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[134]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[135]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[136]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[137]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[138]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[139]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[140]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[141]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[142]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[143]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[144]] = create_species_dict('Flowers_male', 'Flowers_Female') # Blue Pine\n",
    "handbook_dicts[all_species[145]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[146]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[147]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[148]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[149]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[150]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[151]] = create_species_dict('Flowers_open', 'Fruits_open') # Indian Charcoal Tree\n",
    "handbook_dicts[all_species[152]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[153]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[154]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[155]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[156]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[157]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[158]] = create_species_dict('Flowers_open')\n",
    "handbook_dicts[all_species[159]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[160]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Mallika Mango\n",
    "handbook_dicts[all_species[161]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[162]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[163]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[164]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[165]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[166]] = create_species_dict('Flowers_open','Fruits_open') # Mohru Oak\n",
    "handbook_dicts[all_species[167]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[168]] = create_species_dict('Flowers_bud', 'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[169]] = create_species_dict('Flowers_male', 'Flowers_Female')\n",
    "handbook_dicts[all_species[170]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[171]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[172]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Chosa Mango\n",
    "handbook_dicts[all_species[173]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "handbook_dicts[all_species[174]] = create_species_dict('Flowers_male', 'Flowers_Female', 'Fruits_open') # Olour Mango\n",
    "handbook_dicts[all_species[175]] = create_species_dict('Flowers_open','Fruits_open')\n",
    "handbook_dicts[all_species[176]] = create_species_dict('Flowers_bud', 'Flowers_male', 'Flowers_Female', 'Fruits_open')\n",
    "\n",
    "# Replace Incorrect -2 Values\n",
    "for species in all_species:\n",
    "    species_df = df[df['Species_name'] == species]\n",
    "    species_dict = handbook_dicts[species]\n",
    "    for phenophase in phenophases:\n",
    "        if species_dict[phenophase] == 0:\n",
    "            false_positive_idx = species_df.index[species_df[phenophase] == -2] # Indices of reports that incorrectly assign -2 values (false positive) to phenophases that DO appear in the species\n",
    "            df.loc[false_positive_idx, phenophase] = np.full(len(false_positive_idx),np.nan) # turn into NaN so they will be dropped\n",
    "            \n",
    "        if species_dict[phenophase] == 1:\n",
    "            false_negative_idx = species_df.index[species_df[phenophase] != -2] # Indices of reports that incorrectly assign values other than -2 (false negative) to phenophases that DO NOT appear in the species\n",
    "            df.loc[false_negative_idx, phenophase] = np.full(len(false_negative_idx),-2.0) # convert all values for the absent phenophase to -2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7a26e",
   "metadata": {},
   "source": [
    "# Combining Mango Varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f675e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combining all mango varieties under the Species_name of Mango (all varieties)- Mangifera indica\n",
    "df['Species_name'] = df['Species_name'].replace(to_replace=r'\\w* Mango- Mangifera indica', value='Mango (all varieties)- Mangifera indica', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56c03",
   "metadata": {},
   "source": [
    "# Filling in Missing States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c330e936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_shapefile = gpd.read_file(\"india/gadm41_IND_3.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80bd420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamil Nadu\n"
     ]
    }
   ],
   "source": [
    "# Function for filling state_name attribute based on coordinates for observations with NA state_name\n",
    "def find_indian_state(latitude, longitude, gdf):\n",
    "    point = Point(longitude, latitude)\n",
    "    \n",
    "    for _, state in gdf.iterrows():\n",
    "        if state['geometry'].contains(point):\n",
    "            return state['NAME_1']\n",
    "    return None\n",
    "\n",
    "state = find_indian_state(13.07248, 80.24340, states_shapefile)\n",
    "print(state) # IF THE FUNCTION WORKS THIS SHOULD OUTPUT TAMIL NADU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "309f4775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.050238847732543945 seconds elapsed; 0.0% Done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds elapsed; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(observations_missing_state_name)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% Done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfind_indian_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLong\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates_shapefile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# In case any states are labeled as a name inconsistent with our dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m, in \u001b[0;36mfind_indian_state\u001b[0;34m(latitude, longitude, gdf)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_indian_state\u001b[39m(latitude, longitude, gdf):\n\u001b[1;32m      3\u001b[0m     point \u001b[38;5;241m=\u001b[39m Point(longitude, latitude)\n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNAME_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:1542\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1540\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1542\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1544\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/geopandas/geodataframe.py:1639\u001b[0m, in \u001b[0;36mGeoDataFrame._constructor_sliced.<locals>._geodataframe_constructor_sliced\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_sliced\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;124;03m    A specialized (Geo)Series constructor which can fall back to a\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;124;03m    Series if a certain operation does not produce geometries:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03m      checking the identity of the index)\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1639\u001b[0m     srs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m     is_row_proxy \u001b[38;5;241m=\u001b[39m srs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_geometry_type(srs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_row_proxy:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m         object_index\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[1;32m    611\u001b[0m     ):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:1190\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mlib.pyx:2728\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/_config/__init__.py:55\u001b[0m, in \u001b[0;36musing_pyarrow_string_dtype\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     _mode_options \u001b[38;5;241m=\u001b[39m _global_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _mode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnullable_dtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21musing_pyarrow_string_dtype\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     56\u001b[0m     _mode_options \u001b[38;5;241m=\u001b[39m _global_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _mode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer_string\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fill any missing state names in dataset\n",
    "# !!! Warning: This process take ~2.1 hours !!!\n",
    "import time\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "observations_missing_state_name = df[df[\"State_name\"].isna()].drop(['State_name'], axis=1).dropna(how='any')\n",
    "for idx, row in observations_missing_state_name.iterrows():\n",
    "    if (counter % 1000) == 0:\n",
    "        print(f\"{counter}: {time.time()-start_time} seconds elapsed; {counter/len(observations_missing_state_name)*100}% Done\")\n",
    "    df.at[idx, \"State_name\"] = find_indian_state(row[\"Lat\"], row[\"Long\"], states_shapefile)\n",
    "    counter += 1\n",
    "# In case any states are labeled as a name inconsistent with our dataset\n",
    "df['State_name'] = df['State_name'].replace('Andaman and Nicobar', 'Andaman and Nicobar Islands')\n",
    "df['State_name'] = df['State_name'].replace('NCT of Delhi', 'Delhi')\n",
    "print(f\"Finished in {time.time()-start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746623fc",
   "metadata": {},
   "source": [
    "# Dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e449bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rid of NA values and sort by species name\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.dropna()\n",
    "df = df.sort_values(by='Species_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a32b7",
   "metadata": {},
   "source": [
    "# Reformatting & Adding Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformats df to Year, Week formatting to match the reference data\n",
    "df[\"Date_of_observation\"] = pd.to_datetime(df[\"Date_of_observation\"], format='mixed')\n",
    "df[\"Year\"] = df[\"Date_of_observation\"].dt.isocalendar().year\n",
    "df[\"Week\"] = df[\"Date_of_observation\"].dt.dayofyear // (366/48+0.0000000000001) # Weeks duration varies between 7 or 8 days\n",
    "df[\"Week\"] = df[\"Week\"].astype(int)\n",
    "# dt.dayofyear gives an index starting at 1, thus use 366 for leap years\n",
    "# Add 0.0000000000001 bias so week is in range [0,47] instead of [0,48]\n",
    "\n",
    "# !!! Use the following instead if 52 weeks are wanted !!!\n",
    "# df[\"Year\"] = df[\"Date_of_observation\"].dt.isocalendar().week\n",
    "# Warning: 52nd week will only be 1 or 2 days depending on if it's a leap year or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b0e3b",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for anomaly_detection_overall\n",
    "def outlier_detection(df, num_trees=500): # Returns list of indices of observations deemed outliers by isolation forests\n",
    "    df = df.drop([\"Date_of_observation\", \"Observation_ID\", \"User_id\", \"User_Tree_id\", \"State_name\", \"Species_name\", \"Year\"], axis=1)\n",
    "    \n",
    "    model = IsolationForest(n_estimators = num_trees, verbose = 1, random_state = 42)\n",
    "    \n",
    "    invalid_indices = []\n",
    "    \n",
    "    for week in df[\"Week\"].sort_values().unique():\n",
    "        week_df = df[df[\"Week\"] == week]\n",
    "        week_df = week_df.drop(\"Week\", axis=1)\n",
    "        \n",
    "        model.fit(week_df)\n",
    "        preds = model.predict(week_df)\n",
    "        week_df[\"Predictions\"] = preds\n",
    "        \n",
    "        invalid_indices += list(week_df[week_df[\"Predictions\"] == -1].index)\n",
    "    return invalid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection_overall(df, min_observations_for_outlier_detection):\n",
    "    start_time = time.time()\n",
    "    invalid_indices = []\n",
    "    states = df[\"State_name\"].unique()\n",
    "    for state in states:\n",
    "        print(f\"**********{state}**********\")\n",
    "        state_start_time = time.time()\n",
    "        state_df = df[df[\"State_name\"] == state]\n",
    "        years = state_df[\"Year\"].sort_values().unique()\n",
    "        outliers_state = 0\n",
    "        for year in years:\n",
    "            print(f\"**********{year}**********\")\n",
    "            year_start_time = time.time()\n",
    "            state_year_df = state_df[state_df[\"Year\"] == year]\n",
    "            species_list = state_year_df[\"Species_name\"].unique()\n",
    "            outliers_year = 0\n",
    "            for species in species_list:\n",
    "                species_state_year_df = state_year_df[state_year_df[\"Species_name\"] == species]\n",
    "                if len(species_state_year_df) > min_observations_for_outlier_detection:\n",
    "                    species_start_time = time.time()\n",
    "                    outliers = outlier_detection(species_state_year_df)\n",
    "                    outliers_year += len(outliers)\n",
    "                    outliers_state += len(outliers)\n",
    "                    invalid_indices += outliers\n",
    "                    print(f\"{len(outliers)}/{len(species_state_year_df)} observations invalid in {species} in {year} in {state}\")\n",
    "                    print(f\"Finished {species} in {state} during {year} in {time.time()-species_start_time} seconds\")\n",
    "            print(f\"{len(outliers_year)}/{len(state_year_df)} observations invalid in {year} in {state}\")\n",
    "            print(f\"Finished {state} during {year} in {time.time()-year_start_time} seconds\")\n",
    "        print(f\"{len(outliers_state)}/{len(state_df)} observations invalid in {state}\")\n",
    "        print(f\"Finished {state} in {time.time()-state_start_time} seconds\")\n",
    "    print(f\"{len(invalid_indices)}/{len(df)} observations invalid overall\")\n",
    "    print(f\"Finished completely in {time.time()-start_time} seconds\")\n",
    "    return invalid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection on all citizen data and drop any anomalies\n",
    "invalid_indices = anomaly_detection_overall(df, 15*52) # Choose 15*52 as the min num of observations because it means there's an average of 15 observations per week\n",
    "df = df.drop(invalid_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211c964",
   "metadata": {},
   "source": [
    "# Species ID <-> Name Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ac7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lookup dicts for id -> name and name -> id from species_codes.csv\n",
    "species_codes = pd.read_csv(\"species codes.csv\", encoding='unicode_escape')\n",
    "\n",
    "species_id_to_name = {}\n",
    "species_name_to_id = {}\n",
    "\n",
    "for i, row in species_codes.iterrows():\n",
    "    species_id_to_name[row[\"species_id\"]] = \"{}-{}\".format(row[\"species_primary_common_name\"], row[\"species_scientific_name\"])\n",
    "    species_name_to_id[\"{}-{}\".format(row[\"species_primary_common_name\"], row[\"species_scientific_name\"]).lower().replace(\" \", \"\")] = row[\"species_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632e20f",
   "metadata": {},
   "source": [
    "# Encoding and Decoding Species ID & Species Names in Citizen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update names in citizen data\n",
    "# NEEDS SPECIES_ID_TO_NAME AND SPECIES_NAME_TO_ID ALREADY DEFINED\n",
    "for i, row in df.iterrows():\n",
    "    name = row[\"Species_name\"].lower().replace(\" \", \"\")\n",
    "\n",
    "    if name == \"arjuntree-terminaliaarjuna\": # if statements to catch any misspellings or missing entries in species codes.csv\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1083]\n",
    "        continue\n",
    "    if name == \"axlewoodtree-anogeissuslatifolia\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1009]\n",
    "        continue\n",
    "    if name == \"chiku-sapodilla-manilkarazapota\\xa0\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1188]\n",
    "        continue\n",
    "    if name == \"dyer'soleander-wrightiatinctoria\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1181]\n",
    "        continue\n",
    "    if name == \"ficusmollis-softfig\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1197]\n",
    "        continue\n",
    "    if name == \"frangipani-templetree-plumeriarubra\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1176]\n",
    "        continue\n",
    "    if name == \"garuga-kharpat-garugapinnata\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1038]\n",
    "        continue\n",
    "    if name == \"ghostrree-sterculiaurens\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1078]\n",
    "        continue\n",
    "    if name == \"indianfrankincense-boswelliaserrata\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1195]\n",
    "        continue\n",
    "    if name == \"indiancoraltree-erythrinaindica\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1034]\n",
    "        continue\n",
    "    if name == \"kadamba-neolamarckiacadamba\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1058]\n",
    "        continue\n",
    "    if name == \"lanneacoromandelica-indianashtree\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1194]\n",
    "        continue\n",
    "    if name == \"mexicanoleander-yellowoleander-cascabelathevetia\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1177]\n",
    "        continue\n",
    "    if name == \"nightfloweringjasmine-harsingar-nyctanthesarbor-tristis\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1059]\n",
    "        continue\n",
    "    if name == \"prosopiscineraria-khejri\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1201]\n",
    "        continue\n",
    "    if name == \"raintree-samaneasaman\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1162]\n",
    "        continue\n",
    "    if name == \"redsilk-cotton-bombaxceiba\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1015]\n",
    "        continue\n",
    "    if name == \"whitesilk-cotton-ceibapentandra\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1021]\n",
    "        continue\n",
    "    if name == \"yellow-silkcottontree-cochlospermumreligiosum\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1023]\n",
    "        continue\n",
    "    if name == \"karkat-dogteak-dilleniapentagyna\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1032]\n",
    "        continue\n",
    "    if name == \"chosamango-mangiferaindica\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1108]\n",
    "        continue\n",
    "    if name == \"falsewhiteteak-mallotusnudiflorus\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1088]\n",
    "        continue\n",
    "    if name == \"floss-silktree-ceibaspeciosa\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1022]\n",
    "        continue\n",
    "    if name == \"largesebesten-bairola-cordiawallichii\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1026]\n",
    "        continue\n",
    "    if name == \"roxburghskydia-pulia-kydiacalycina\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1044]\n",
    "        continue\n",
    "    if name == \"wildrose-rosawebbiana\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1206]\n",
    "        continue\n",
    "    if name == \"albiziaodoratissima-blacksiris\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1199]\n",
    "        continue\n",
    "    if name == \"anogeissuspendula-kardhai\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1198]\n",
    "        continue\n",
    "    if name == \"brokenbonestree-oroxylumindicum\":\n",
    "        df.loc[i, \"Species_name\"] = \"Broken Bones Tree-Oroxylum Indicum\"\n",
    "        continue\n",
    "    if name == \"pyinmatree-andamancrapemyrtle-lagerstroemiahypoleuca\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1216]\n",
    "        continue\n",
    "    if name == \"crataevareligiosa-garlic-peartree\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1196]\n",
    "        continue\n",
    "    if name == \"guh-de-three-leafcapertree-cratevaadansonii\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1217]\n",
    "        continue\n",
    "    if name == \"aabehayatmango-mangiferaindica\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1091]\n",
    "        continue\n",
    "    if name == \"bedu-punjabfig-ficuspalmata\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1235]\n",
    "        continue\n",
    "    if name == \"chinar-platanusorientalis\":\n",
    "        df.loc[i, \"Species_name\"] = \"Chinar-Platanus Orientalis\"\n",
    "        continue\n",
    "    if name == \"prunusnepalensis-sohiong\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1192]\n",
    "        continue\n",
    "    if name == \"tecomellaundulata-roheda\":\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[1200]\n",
    "        continue\n",
    "    if name == \"tigersmilkspruce-falconeriainsignis\":\n",
    "        df.loc[i, \"Species_name\"] = \"Tiger's Milk Spruce-Falconeria Insignis\"\n",
    "        continue\n",
    "    if species_name_to_id[name]:\n",
    "        df.loc[i, \"Species_name\"] = species_id_to_name[species_name_to_id[name]] # species dictionaries to undo the .lower().replace(\" \",\"\") formatting\n",
    "df.insert(loc = 4, column = 'Species_id', value = [species_name_to_id.get(species.lower().replace(\" \",\"\"), np.nan) for species in df[\"Species_name\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f4694",
   "metadata": {},
   "source": [
    "# Save Updated Citizen Data in One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a837d-547c-46ea-bf0d-103ffcf9ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated all_data.csv\n",
    "df.to_csv('updated_alldata.csv', index=False) # SAVED IT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86773a",
   "metadata": {},
   "source": [
    "# Make Directories for Citizen and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd18c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to citizen and reference data. create if they do not exist\n",
    "os.makedirs(\"all data/citizen\", exist_ok=True)\n",
    "os.makedirs(\"all data/reference\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa8a9e",
   "metadata": {},
   "source": [
    "# State DFs to citizenData folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e6c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for state_name in df[\"State_name\"].unique():\n",
    "    state_df = df[df[\"State_name\"] == state_name]\n",
    "    state_name = state_name.replace(\" \",\"_\").lower() # Reformat state names to lowercase with _ instead of spaces\n",
    "    state_df.to_csv(f\"all data/citizen/{state_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb0ddd",
   "metadata": {},
   "source": [
    "# Reference Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "688529ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicts and Functions\n",
    "code_to_attribute_dict = {'FL': 'Leaves_fresh', 'ML': 'Leaves_mature', 'DL': 'Leaves_old', \n",
    "                          'BD': 'Flowers_bud', 'OF': 'Flowers_open', 'MF': 'Flowers_male', \n",
    "                          'FF': 'Flowers_Female', 'UFR': 'Fruits_unripe', 'RFR': 'Fruits_ripe', \n",
    "                          'OFR': 'Fruits_open'}\n",
    "code_to_category_dict = {'NA': None, '': None, '0': 0, '1': 1, '2': 2} #TODO - what should map to -1?\n",
    "\n",
    "def code_to_attribute_category_tuple(code):\n",
    "    code_attr_tup = code.split('_')\n",
    "    code_attr_tup[0] = code_to_attribute_dict[code_attr_tup[0]]\n",
    "    code_attr_tup[1] = code_to_category_dict[code_attr_tup[1]]\n",
    "    return tuple(code_attr_tup)\n",
    "\n",
    "def get_duplicates_df(df):\n",
    "    duplicates_df = pd.DataFrame({'species_id': [], 'all_same': []})\n",
    "    for species_id in df['species_id'].unique():\n",
    "        df_filtered = df[df['species_id'] == species_id]\n",
    "        if len(df_filtered) > 1:\n",
    "            # see if categorical vectors are all the same:\n",
    "            all_equal = True\n",
    "            for colname in df.columns[3:-2]:\n",
    "                all_equal = all_equal and df_filtered[colname].nunique() == 1\n",
    "            duplicates_df.loc[len(duplicates_df) + 1] = pd.Series({'species_id': species_id, 'all_same': all_equal})\n",
    "    return duplicates_df\n",
    "\n",
    "def clean_df(df):\n",
    "    # TODO:\n",
    "    # - get rid of null values\n",
    "\n",
    "    # get rid of duplicate rows\n",
    "    print(\"getting rid of duplicates\")\n",
    "    duplicates_df = get_duplicates_df(df)\n",
    "    for i in range(len(duplicates_df)):\n",
    "        dup_id = duplicates_df.iloc[i]['species_id']\n",
    "        drop_idx = list(df['species_id']).index(dup_id)\n",
    "        df = df.drop(index=drop_idx)\n",
    "    print(\"got rid of duplicates\")\n",
    "    # new columns: everything in df that is not a month, plus the 10 categorical codes, plus a 'week' column\n",
    "    week_codes = ['Jan_wk1', 'Jan_wk2', 'Jan_wk3', 'Jan_wk4', 'Feb_wk1', \n",
    "                   'Feb_wk2', 'Feb_wk3', 'Feb_wk4', 'Mar_wk1', 'Mar_wk2',\n",
    "                   'Mar_wk3', 'Mar_wk4', 'Apr_wk1', 'Apr_wk2', 'Apr_wk3', 'Apr_wk4',\n",
    "                   'May_wk1', 'May_wk2', 'May_wk3', 'May_wk4', 'Jun_wk1', 'Jun_wk2',\n",
    "                   'Jun_wk3', 'Jun_wk4', 'Jul_wk1', 'Jul_wk2', 'Jul_wk3', 'Jul_wk4',\n",
    "                   'Aug_wk1', 'Aug_wk2', 'Aug_wk3', 'Aug_wk4', 'Sep_wk1', 'Sep_wk2',\n",
    "                   'Sep_wk3', 'Sep_wk4', 'Oct_wk1', 'Oct_wk2', 'Oct_wk3', 'Oct_wk4',\n",
    "                   'Nov_wk1', 'Nov_wk2', 'Nov_wk3', 'Nov_wk4', 'Dec_wk1', 'Dec_wk2','Dec_wk3', 'Dec_wk4']\n",
    "    \n",
    "    cat_codes = ['Leaves_fresh', 'Leaves_mature', 'Leaves_old', 'Flowers_bud',\n",
    "       'Flowers_open', 'Flowers_male', 'Flowers_Female', 'Fruits_unripe',\n",
    "       'Fruits_ripe', 'Fruits_open']\n",
    "\n",
    "    base_cols = [not_week_code for not_week_code in filter(lambda c: c not in week_codes, list(df.columns))]\n",
    "    try:\n",
    "        base_cols.remove('created_at')\n",
    "    except:\n",
    "        print(\"WARNING: created_at column not found\")\n",
    "    \n",
    "    new_cols = base_cols + ['week'] + cat_codes\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=new_cols)\n",
    "\n",
    "    num_idxs = len(df)\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx % 10 == 0:\n",
    "            print(\"{} % done\".format(100 * idx / num_idxs))\n",
    "        for week_idx, week_name in enumerate(week_codes):\n",
    "            new_datapoint = {}\n",
    "            for old_colname in base_cols:\n",
    "                new_datapoint[old_colname] = row[old_colname]\n",
    "            new_datapoint['week'] = week_idx\n",
    "            cat_vector_for_week = row[week_name]\n",
    "\n",
    "            # make nan map to a cat vector of all Nones\n",
    "            # print(type(cat_vector_for_week), cat_vector_for_week)\n",
    "            if not isinstance(cat_vector_for_week, str):\n",
    "                if math.isnan(cat_vector_for_week):\n",
    "                    for attr_name in code_to_attribute_dict.values():\n",
    "                        new_datapoint[attr_name] = None\n",
    "                    new_df.loc[len(new_df)] = new_datapoint\n",
    "                    continue\n",
    "            \n",
    "            cat_vector_list = list(map(code_to_attribute_category_tuple, cat_vector_for_week.split(\",\")))\n",
    "            for (attr, cat) in cat_vector_list:\n",
    "                new_datapoint[attr] = cat\n",
    "\n",
    "            # add new datapoint to df\n",
    "            new_df.loc[len(new_df)] = new_datapoint\n",
    "            # remove unnamed columns if they exist\n",
    "            for col in new_df.columns:\n",
    "                if 'Unnamed' in col or col == 'id':\n",
    "                    new_df = new_df.drop(col, axis=1)\n",
    "            new_df['species_name'] = new_df['species_id'].map(species_id_to_name) # Adding species_name column\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe2b27",
   "metadata": {},
   "source": [
    "# Saving Cleaned Reference Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72c26c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning pvt_andaman_and_nicobar_islands.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_rajasthan.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "100.0 % done\n",
      "cleaning pvt_arunachal_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_madhya_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_assam.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_jharkhand.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_maharastra.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_karnataka.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_jammu_and_kashmir.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_pvt_haryana.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_manipur.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_delhi.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_tripura.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_odisha.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_tamil_nadu.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_gujarat.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_andhra_pradesh.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_bihar.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_kerala.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.184100418410042 % done\n",
      "8.368200836820083 % done\n",
      "12.552301255230125 % done\n",
      "16.736401673640167 % done\n",
      "20.92050209205021 % done\n",
      "25.10460251046025 % done\n",
      "29.288702928870293 % done\n",
      "33.47280334728033 % done\n",
      "37.65690376569037 % done\n",
      "41.84100418410042 % done\n",
      "46.02510460251046 % done\n",
      "50.2092050209205 % done\n",
      "54.39330543933055 % done\n",
      "58.57740585774059 % done\n",
      "62.76150627615063 % done\n",
      "66.94560669456067 % done\n",
      "71.1297071129707 % done\n",
      "75.31380753138075 % done\n",
      "79.4979079497908 % done\n",
      "83.68200836820084 % done\n",
      "87.86610878661088 % done\n",
      "92.05020920502092 % done\n",
      "96.23430962343096 % done\n",
      "100.418410041841 % done\n",
      "cleaning pvt_puducherry.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "58.333333333333336 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n",
      "cleaning pvt_meghalaya.csv\n",
      "getting rid of duplicates\n",
      "got rid of duplicates\n",
      "0.0 % done\n",
      "4.166666666666667 % done\n",
      "8.333333333333334 % done\n",
      "12.5 % done\n",
      "16.666666666666668 % done\n",
      "20.833333333333332 % done\n",
      "25.0 % done\n",
      "29.166666666666668 % done\n",
      "33.333333333333336 % done\n",
      "37.5 % done\n",
      "41.666666666666664 % done\n",
      "45.833333333333336 % done\n",
      "50.0 % done\n",
      "54.166666666666664 % done\n",
      "62.5 % done\n",
      "66.66666666666667 % done\n",
      "70.83333333333333 % done\n",
      "75.0 % done\n",
      "79.16666666666667 % done\n",
      "83.33333333333333 % done\n",
      "87.5 % done\n",
      "91.66666666666667 % done\n",
      "95.83333333333333 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "# clean all old pvt dataframes, put in ./reference_data\n",
    "\n",
    "for tablename in os.listdir('./pvttables_raw/'):\n",
    "    if tablename == '.DS_Store':\n",
    "        continue\n",
    "    print(\"cleaning {}\".format(tablename))\n",
    "    ref_df = pd.read_csv('./pvttables_raw/{}'.format(tablename), sep=';')\n",
    "    tablename = tablename.replace(\"pvt_\",\"\")\n",
    "    if tablename == 'maharastra.csv':\n",
    "        tablename = 'maharashtra.csv'\n",
    "    new_df = clean_df(ref_df)\n",
    "    new_df.to_csv('./all data/reference/{}'.format(tablename), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
